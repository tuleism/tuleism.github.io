{"hash":"25f39d56192163c1a92a1c3129d3169cad380774","data":{"metadata":{"siteName":"Random.nextBlog","siteUrl":"https://tuleism.github.io","siteDescription":"Tech Blog on Scala, Programming, Data, Search and Distributed Systems"},"doc":{"title":"Parallel, Back-pressured Kafka Consumer","slug":"parallel-backpressured-kafka-consumer","path":"/blog/2021/parallel-backpressured-kafka-consumer/","date":"14. September 2021","timeToRead":11,"content":"<h2 id=\"introduction\"><a href=\"#introduction\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Introduction</h2>\n<p><a href=\"https://www.confluent.io/learn/kafka-tutorial/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Almost</a> <a href=\"http://cloudurable.com/blog/kafka-tutorial-kafka-consumer/index.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">every</a> <a href=\"https://www.oreilly.com/library/view/kafka-the-definitive/9781491936153/ch04.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Kafka Consumer tutorial</a> structure their code like this:</p>\n<pre class=\"language-java line-numbers\"><code class=\"language-java\"><span class=\"token class-name\">KafkaConsumer</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">String</span><span class=\"token punctuation\">,</span> <span class=\"token class-name\">Payment</span><span class=\"token punctuation\">></span></span> consumer <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">KafkaConsumer</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token punctuation\">></span></span><span class=\"token punctuation\">(</span>props<span class=\"token punctuation\">)</span>\n<span class=\"token comment\">// Subscribe to Kafka topics</span>\nconsumer<span class=\"token punctuation\">.</span><span class=\"token function\">subscribe</span><span class=\"token punctuation\">(</span>topics<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n<span class=\"token keyword\">while</span> <span class=\"token punctuation\">(</span><span class=\"token boolean\">true</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n    <span class=\"token comment\">// Poll Kafka for new messages</span>\n    <span class=\"token class-name\">ConsumerRecords</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">String</span><span class=\"token punctuation\">,</span> <span class=\"token class-name\">String</span><span class=\"token punctuation\">></span></span> records <span class=\"token operator\">=</span> consumer<span class=\"token punctuation\">.</span><span class=\"token function\">poll</span><span class=\"token punctuation\">(</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token comment\">// Processing logic</span>\n    <span class=\"token keyword\">for</span> <span class=\"token punctuation\">(</span><span class=\"token class-name\">ConsumerRecord</span><span class=\"token generics\"><span class=\"token punctuation\">&lt;</span><span class=\"token class-name\">String</span><span class=\"token punctuation\">,</span> <span class=\"token class-name\">String</span><span class=\"token punctuation\">></span></span> <span class=\"token keyword\">record</span> <span class=\"token operator\">:</span> records<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token function\">doSomething</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">record</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span class=\"line-numbers-rows\" aria-hidden=\"true\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>Basically we set up our <a href=\"https://javadoc.io/doc/org.apache.kafka/kafka-clients/latest/org/apache/kafka/clients/consumer/KafkaConsumer.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Kafka Consumer</a>, <code class=\"language-text\">subscribe</code> it to some <a href=\"https://dattell.com/data-architecture-blog/what-is-a-kafka-topic/\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Kafka topics</a> and then go into an infinite loop where, on each iteration, we <code class=\"language-text\">poll</code> some messages from these topics and process them one by one.\nWe can call this the <strong>poll-then-process loop</strong>.</p>\n<p>This is fairly simple, easy to put into practice, and people may have been using it in production without any issue.\nHowever, there are various problems with this model, which we're going into more details in the next section.</p>\n<h2 id=\"the-problems-with-the-poll-then-process-loop\"><a href=\"#the-problems-with-the-poll-then-process-loop\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>The problems with the poll-then-process loop</h2>\n<h3 id=\"1-it-is-not-the-expected-way-to-poll\"><a href=\"#1-it-is-not-the-expected-way-to-poll\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>1. It is not the \"expected\" way to poll</h3>\n<p>Looking at the code above, we developers might think that <code class=\"language-text\">poll</code> acts as a way to signal <strong>demand</strong> to Kafka.\nOur consumer only <code class=\"language-text\">poll</code>s to pull in more messages when it has finished working on previous ones.\nIf its processing rate is slow, Kafka would act as the <strong>shock absorber</strong>, ensuring we don't lose any message even when the producing rate is much higher.</p>\n<p>On the other hand, when processing rate is slow, the <strong>interval</strong> between consecutive <code class=\"language-text\">poll</code>s also <strong>increases</strong>.\nThis is problematic since there is a default (5 minutes) upper bound on it with the <a href=\"https://docs.confluent.io/platform/current/installation/configuration/consumer-configs.html#consumerconfigs_max.poll.interval.ms\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">max.poll.interval.ms</a> configuration:</p>\n<blockquote>\n<p><strong>max.poll.interval.ms</strong></p>\n<p>The maximum delay between invocations of poll() when using consumer group management. This places an upper bound on the amount of time that the consumer can be idle before fetching more records. If poll() is not called before expiration of this timeout, then the consumer is considered failed and the group will rebalance in order to reassign the partitions to another member. </p>\n</blockquote>\n<p>In other words, if our consumer doesn't call <code class=\"language-text\">poll</code> at least once every <code class=\"language-text\">max.poll.interval.ms</code>, to Kafka, it's as good as dead.\nWhen this happens, Kafka follows up with a <a href=\"https://medium.com/streamthoughts/apache-kafka-rebalance-protocol-or-the-magic-behind-your-streams-applications-e94baf68e4f2\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">rebalance</a> process to distribute the current work of the dead consumer to the rest of its <a href=\"https://docs.confluent.io/platform/current/clients/consumer.html#consumer-groups\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">consumer group</a>.\nThis introduces more overhead and delay into an already slow processing rate.</p>\n<p>Worse yet, if the processing causes slowness in one consumer, chances are, it would cause the same problem for other consumers taking over its work.\nMoreover, the presumed dead consumer can also cause <strong>rebalance</strong> when it attempts to rejoin the group on its next poll (remember it's an <em>infinite</em> loop!).\nBoth of these makes <strong>rebalance</strong> happen again and again, slowing consumption even more.</p>\n<p>Now, there is another configuration which can help with this situation:</p>\n<blockquote>\n<p><strong>max.poll.records</strong></p>\n<p>The maximum number of records returned in a single call to poll(). Note, that max.poll.records does not impact the underlying fetching behavior. The consumer will cache the records from each fetch request and returns them incrementally from each poll.</p>\n</blockquote>\n<p>With this set to a lower value, our consumer will process fewer messages per <code class=\"language-text\">poll</code>. Thus, the <code class=\"language-text\">poll</code> interval will decrease.\nAlternatively, we can also increase <code class=\"language-text\">max.poll.interval.ms</code> to a bigger value. This should solve the problem temporarily if we can't move away from the <strong>poll-then-process</strong> loop.\nNevertheless, it is not ideal.</p>\n<p>Firstly, these configurations are set when we start our consumers, but whether they work or not depends on the messages or the applications.\nWe may set them specifically for each application, but in the end, we're playing a <strong>guessing game</strong> and pray that we're lucky.</p>\n<p>Secondly, in the worst case, it may take <strong>twice</strong> the <code class=\"language-text\">max.poll.interval.ms</code> duration for the <strong>rebalance</strong> process to start:</p>\n<ol>\n<li>Kafka has to wait <code class=\"language-text\">max.poll.interval.ms</code> to <strong>detect</strong> that our consumer is not <code class=\"language-text\">poll</code>ing anymore.</li>\n<li>When Kafka decides to <strong>rebalance</strong> the group, other consumers are only <strong>made aware</strong> of this decision on their <strong>next</strong> <code class=\"language-text\">poll</code>.</li>\n</ol>\n<p>We never want <strong>rebalance</strong> to take even more time, so setting a higher <code class=\"language-text\">max.poll.interval.ms</code> is not great.</p>\n<p>Finally, these configurations implies that our consumer is \"expected\" to <code class=\"language-text\">poll</code> frequently, at least once every <code class=\"language-text\">max.poll.interval.ms</code>, no matter what kind of processing it is doing.\nBy not incorporating this expectation, the <strong>poll-then-process</strong> loop is not only <strong>misleading</strong> to developers but also doomed to fail.</p>\n<h3 id=\"2-message-processing-is-synchronous\"><a href=\"#2-message-processing-is-synchronous\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>2. Message processing is synchronous</h3>\n<p>Kafka only guarantees the <strong>order</strong> of messages <strong>within one partition</strong>. Messages from different partitions are unrelated and can be processed in parallel.\nThat's why in Kafka, the <strong>number of partition</strong> in a topic is the unit of <strong>parallelism</strong>.</p>\n<p>In theory, we could easily achieve maximum parallelism by having <strong>as many</strong> consumers running as the number of partitions on a topic.\nHowever, in reality, this is too much overhead, not to mention its impact on increasing the chance for <strong>rebalance</strong>, since there are more consumers that can come and go.</p>\n<p>If we look at our <a href=\"#introduction\">consumer code</a> again, it can subscribe to multiple topics and possibly receive messages from multiple partitions.\nYet, when it comes to processing these messages, it does so one by one. This is not optimal.</p>\n<p>Now, assuming our processing logic is very simple, could we just use a <a href=\"https://en.wikipedia.org/wiki/Thread_pool\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">thread pool</a> to parallelize it?\nFor example, by submitting one processing task to the thread pool, for each message?</p>\n<p>Well, kind of. It only works if we don't care about processing <strong>ordering</strong> and <strong>guarantees</strong> like <em>at-most-once</em>, <em>at-least-once</em>, etc. So it is not very useful in practice.</p>\n<h2 id=\"a-better-model\"><a href=\"#a-better-model\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>A better model</h2>\n<h3 id=\"overview\"><a href=\"#overview\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Overview</h3>\n<p>The many setbacks of the <strong>poll-then-process</strong> loop come from the fact that different concerns - <code class=\"language-text\">poll</code>ing, processing, offsets committing - are mixed together.\nAs a result, when we <strong>divide</strong> them into separated components, we end up with an improved model which supports <strong>parallel</strong> processing and <strong>back-pressure</strong> properly.\nEach component is described in more details below.</p>\n<p><img class=\"g-image g-image--lazy g-image--loading\" src=\"data:image/svg+xml,%3csvg fill='none' viewBox='0 0 693 831' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-abb93788319a705f3cba6290ffe0c1b4'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-abb93788319a705f3cba6290ffe0c1b4)' width='693' height='831' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAABNCAYAAAAW92IAAAAACXBIWXMAAAsSAAALEgHS3X78AAAM5klEQVR42t2bh1cUSxbG55/d9e1bOXuOG9THe7rG9RkwZzErZsGAARUjIhgxYQKMiAoKEgXmbv1q5o41TU/o7hmcY51Tp6t7aqarbt373e/eqomJU%2bLxeKpdsXSpTP317/L06VPfz0uxhBlfzO8HhoaGZMmfi2Xef%2bdIc1OzXKyvl%2bsNDYk%2b43Hbr6RkEY%2bnxv7161fp7OyU9%2b/f29rV1WXv3WdU7r98%2bZIuAMrY6Ki9njxxQmb8%2bz9y5/Zt%2bfWXX6R8xkzp6e5OCYr3lYQQkoNQATCx4eFhGTXzGBkZsQIZHx%2b3lWd8xnP6I4g0AdCJ0tHeITOnz5A//7dI/lFWJtu2bpWa6urUS1wN%2bGGCcF/saACTGhsbS3W7du2anD17Vm7cuGHb7mcfPnzwFwDq/kf571J74qRM%2bctfpeXeXXnU%2blRaPon0D49nGkPxBOF9iU%2b1PZ49k87Tp227o63NTryurk4uX74s58%2bft1eE8Pz585SwJmCACmHrlkopMyC4e9cu%2bduUKUYg5fKx%2b7MMGAv5NBCX4VH/xfATTEGF4FfMmOMfP4oxaul8/do%2b6uvtldem/cwI5aP5jDb15s2b9koBHyYIQFVpX1WVzJszVzo6OmT5sgrZWllpADAhnNGxuHweEltHkwphsDGtFmXyqK8BaGPIYgw5cc/VTCQ%2bOJhQazPZvr4%2ba%2b%2boO/PRti4u7UHT31cAFD78feZv8q9p/5QbjY1p5jHuzAot6Dbv7R2eHKAzOity6pRITY2IAWkxiyL37ye6JPsxzm4D1kwuW0UrEExGE3jS2mo9waNHjyZoh9cNDn4TaTRadfWlSH27GeMzkbae75oRCR%2b89oT9Xrggglu%2beDGhAR4gDM0DvGBIuXXrVgo5VQh%2bwHe/S6TWcKZrRghXTP0ylC6AUEDp90UWhMmfOSPS1CTy7Vua9n4fY341Iwao/aBOrgC8C6OPWg0G1b0QOf5E5KxZpM6v3/HB12PkC3hu%2b%2bpVA077zIvqjKrVixw4IGJQPwrixjJRSp3su3fvfAWQC6CZfM9gAijHxlNWGniF7Hd4PyhvxmKYDg7cuCLjk0HzN28i%2beFYLl4Ns8okAO%2bqer2ApdVJoOwbDs7V6R0H8Q342WsYF1lMAeRrtpT%2bkbh8MoIYMS50YKBf%2bvuzVOPGBsGhu3etzccdf59me3pfSA2I%2b3BrLwgGBe5EO8HWuj5%2bsn4aVwtPp811YGDAtqm0u3t65AtuL8ny4gVnVnkIgAoGjI6Ohgo507EsnmRf7%2bXx48dy/fp1efHihTHhN9LS0mLr27dv7ftgb58/f5YPxs7Hkh4pXoTJpwlgop9PtAkZMwknmCtPfIcA5IThF7sMxV63bp3hNafs/YoVK%2bTw4cOyfv16mTt3rs1DEH2OJP18sXIRGTUALkDgsM%2b4Ha5RkyKuSbkFdb9oCM1tE3Z7C31V%2b4ouANf18FJW6tixY3Ly5ElLhqCPg0m%2bHQ/BulwBIFxNXLx8%2bVLu3LljGO19efXqlTUB1TqitUkXAOWCoZoHDMm4cuWKFQKh5P79%2bw0PuRpZAEyQctcgPL/N5MGCekNsaGMS7e3tP0YD9KoZE1aKoIF72t88tDPI5L0aYOONJ0%2bktrbWxulo2rlz56Snpyf1vUnVgIlUd%2bKA/dxkrkl7%2bzMpLZgV6P/w4UNbacMDMgkgHjLgCawB3hXzEqEgk/cOmt8j6eoK1e/78AG0L5eXKrgXCMsEMwnQfQbSY9%2b9vb0WC6j4frfyPq54hwcPHqSl5YshiFiuQCSXALINiDZZWGV%2bbkIy3wL%2bKEX2mqLfeyOFw34lkwCyrTj9UXMGzcT9tCFINEgBgHGdXvPxw5lAGsAAqYANA0b1tHrTzJkknQqBk79BZcCZJh7FnFQjGLMfODNWnYf2o%2bq4aOvi8Fsx8uVKeCAluCHAh/rJcHHVgEwro6vDD7JCbtwQdYWymZe%2b09UwddskcRg7lVgDTKHNc3CHrDBt%2bsb4QH/MW7Df5uZm38F51dy17yCrHXTPzysIxRhWE3BlPm6BxUKw9DsAK4vOnKkxZWZ0IAJDMlQ0AfVnc4Ef5Z7n9EFysETULNPgiuGzs/0%2bi8FYNdZQSr9z507Zu3dvKqiqrq6WTZs2pYA5JQAe8GWNy/kQ6WoOXWN3VhwBKGMLCmrFqhpYKXfgGSu8atUqWb16tRUQhSh04cKFdvzML8Yq0xH1oWohIOHHWHENgly1g8WVWmGRNIkLzSbAIn4h2uSeFH9DQ4ONbRCW1QA68yUAkMlquXfvnmzfvl0qKirs1WVlaMLRo0fTNIO2agg/jjAViWn79eWeNp8H%2bZ63L89ZUYI45sJqnzlzxoI7fdEG4g3yDW44zu/G3BVXAbjuBTvSe3fnCGTVz3Xbiau37fcsV98w32NszAEBoNEkVpYvX55S/aqqKpk/f35aLGIFoJNCsoqg2egsBUHRv9QKC6MCQO2PHDmS8lCNjY02ueOabpoAdE8NUERNuCIt8nfK0fV5qQGgHwgqucu285UygUwc37sxks0//8jiCsDlAdg97pqUHgkY8g0sqOs6Y9mCiExUuJAkp5ACYJyouFJx1J6EKxVQPHTokCVBaAAaMuGESCE2RkpBCLo9DlZhBqw%2brk/xi0VVBhzLFISonei%2bQKmterbNHG/BXarX8vaJ5bLr7uTJsFKz%2byARJFrhkjwFwrR8gPslOpOJQWoQIrSAlLWGyME2ReIF8Rj5701%2b74%2bNk4Ei60zOkcgQNqiB3wQBqNq3tbXJnj17rC89ffq0zdwCIJquDpsSL1REmK8AmpqarO2D/rBEgiUYbLdz3jGnCXgJT9jJE41pXO5Gl36Vz%2biDT2cVw2yPuX1Z0EuXLvl%2bnnFvUJGfQYOWetoyrPpCOjAjJgNlVSGoINw2FcHzXhBbiVfQ92t/3s2GqzsHXw3wi7ULFfVpeM1giM/JQBGb19TU2KCFNlcqFJYdIo08vQAWJrGqcU5OL%2bAVhkaJGpGFqYAOqswqcHKzrKzM8nLi9KlTp8qOHTtk8eLFMn36dIs9a9askcrKShvCwkNIYbnnB8K8WxfS6yFyCgDg07yAqmnQispjStgi1JQQG2Bl1deuXWvDVLSCsPv48eNWC9iLxBOB3LqXEPbdCNEVQCANKJQJwLs1dsezgM4gMwkLtILNUYQDUlMbksfzNQcQ1QTcTFHgnSGXCYYFQVVFCqsKJ4eiIgwSlZzhZdJUuIce0NSVDwOCmVJlkbbGoghAIzXMgUgNIZC2ImjhyAyRGllcNknfJI%2b/IQA3UTPpAsANFYLI6GYLA%2bEIzObNmy0Irly50h6VIXlJJZMDRpDNRXUxAfeYTpiCJwktAJCb1dC/mYSp4AinzlF5AK%2b8vNzaOWkqkB/QQyDz5s2zJgEA4iXoz9l%2bvAHmE%2bXdoUGQOICVyJa3y1YVP1BlCA72jgZs27bNTprV3rBhg3V9aALub8uWLdYjMAF3m1zzj0HfjQuPZALZ9vLzLWAAqgy7A%2bDQLNycVgIWVpqghStVqbibrQ7rgX44CGL/6gVQa9Qe93fw4EHL02GGGngRvJDF0YMSLosL825wJLIbLKQX0LiA3%2bYZTE9PhyEk3Zz1S9dPuhcAPArpBZgwYAfa4wE4IIn9k8PnnvbSpUvtFlZJeQEE4f7xMN/q9QIEOuoFoL9eL0AQhAfAQ0CI1AswAe%2bfH/Opkb0ApEU3STGFMBXV1a1rSA5eAJQH7ZctW5byAsQFrhfALPgek9fNzjDvLgkvgPqjyqi1Hn5qbW21q8uVlebKZzBC2ooXUU2gZL0AaE%2bqDS8A%2buMF8AYESVwRfEl4gSj7An5eoDf5p0bMC9vUNkRJvQBXPzcY5t0lIwCiOuySqx6v0YqGoO5U3RrXDFJJCSAKD2CFdVU1P6A5Aqq2%2bYw%2bfgKYdBPw/hs7igYwEUAQEkSqTckQGR/MgDYui%2be6kxPFBNx8ZGgBMBANKjSrGrTqRNT2p02bZgnQggULLCfAFeIaZ8%2bebYOjOXPmWNeoJqF5/LDvdpMxoaLBQoXDHFfjfwhMkBQYpGjWrFnWAxD/L1myxHoGMsXECJwthojhEpmAnl0IUhk3QtfMct4CKPQ%2boB6kRBCLFi2yRAfSs3HjRntsDWrMvRKh3bt3W9UHF6JGg9nmk1MDCnV6Q0EQtVQMQBjQXTAALSMkZsW5VyLkpsSKsb8YkyIXv4gM9oeKQ4ZYbfg/KXLID8%2b45/OoPCCfMqkCUCKEm1N3p4cWMA%2bN3OD86nm8GvBTCIBdW2gvlBfeT4DEypMd5hkgqPsCP5UA1ASwf5CfFDi2jgAQiv59DkHo/wh/SgHgzlhldoUQAK6PSbNPoBWh/LQmoCc5SZHDCziIgVskDwgYkgzRBIabEvtpBMAzGCamgPvjOZ4BN0ioTK5AQbHYGvB/YP5djBUQlXwAAAAASUVORK5CYII=' /%3e%3c/svg%3e\" width=\"693\" alt=\"Parallel Kafka Consumer\" data-srcset=\"/assets/static/parallel-kafka-consumer.c19ed0b.28600783a4c9d1eb144a357c98e8292c.png 693w\" data-sizes=\"(max-width: 693px) 100vw, 693px\" data-src=\"/assets/static/parallel-kafka-consumer.c19ed0b.28600783a4c9d1eb144a357c98e8292c.png\"><noscript><img class=\"g-image g-image--lazy g-image--loaded\" src=\"/assets/static/parallel-kafka-consumer.c19ed0b.28600783a4c9d1eb144a357c98e8292c.png\" width=\"693\" alt=\"Parallel Kafka Consumer\"></noscript></p>\n<h3 id=\"work-queues\"><a href=\"#work-queues\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Work Queues</h3>\n<p>The <strong>Work Queues</strong> is the communication channel between <strong>Poller</strong> and <strong>Executor</strong>:</p>\n<ul>\n<li>There is a <em>one-to-one</em> mapping of assigned <a href=\"\">TopicPartition</a>s to <strong>work queues</strong>.\nAfter each <code class=\"language-text\">poll</code>, <strong>Poller</strong> pushes new messages from each partition into its corresponding work queue, <strong>preserving</strong> the original <strong>ordering</strong>.\nEach work queue is also <strong>bounded</strong> with a configurable size. When full, it <strong>back-pressures</strong> <strong>Poller</strong> so that it can follow up with the appropriate actions.</li>\n<li>The work queues are <strong>asynchronous</strong>, which <strong>decouples</strong> polling and message processing, allowing them to happen independently.\nThis is in contrast to the <strong>poll-then-process</strong> loop, where they are two sequential steps within a loop.</li>\n</ul>\n<h3 id=\"poller\"><a href=\"#poller\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Poller</h3>\n<p>In short, <strong>Poller</strong> encapsulates everything related to <code class=\"language-text\">poll</code> in Kafka:</p>\n<ul>\n<li>\n<p>It watches out for <strong>rebalance</strong> events - e.g by registering a <a href=\"https://kafka.apache.org/28/javadoc/org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">ConsumerRebalanceListener</a> - and coordinates other units to handle them.</p>\n<ul>\n<li>For each newly <a href=\"https://kafka.apache.org/28/javadoc/org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html#onPartitionsAssigned(java.util.Collection)\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">assigned</a> <code class=\"language-text\">TopicPartition</code>, it set up a new <strong>work queue</strong>.</li>\n<li>For each <a href=\"https://kafka.apache.org/28/javadoc/org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html#onPartitionsRevoked(java.util.Collection)\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">revoked</a> (or <a href=\"https://kafka.apache.org/28/javadoc/org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html#onPartitionsLost(java.util.Collection)\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">lost</a>) <code class=\"language-text\">TopicPartition</code>,\nit commands both <strong>Executor</strong> and <strong>Offset Manager</strong> to <strong>wrap up</strong> related works and tears down the <strong>corresponding work queue</strong>.</li>\n</ul>\n</li>\n<li>It <code class=\"language-text\">poll</code>s Kafka periodically using a <strong>short</strong> (e.g 50ms), <strong>configurable interval</strong>.\nSince this is many times lower than the default <code class=\"language-text\">max.poll.interval.ms</code>, while also not affected by message processing, we avoid the \"rebalance storm\" that plagues the <strong>poll-then-process</strong> loop.\nKafka won't mistaken our consumer as dead for not <code class=\"language-text\">poll</code>ing often enough. In addition, we would know sooner if another <strong>rebalance</strong> is going to happen.</li>\n<li>When we <code class=\"language-text\">poll</code> more often, we can also use a lower <code class=\"language-text\">max.poll.interval.ms</code> to speed up the <strong>rebalance</strong> process.</li>\n<li>For each <code class=\"language-text\">TopicPartition</code> that the <strong>Executor</strong> cannot keep up with the rate of incoming messages, its corresponding work queue will become full and <strong>back-pressure</strong> the <strong>Poller</strong>.\nThe <strong>Poller</strong> would need to selectively <a href=\"https://kafka.apache.org/28/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html#pause(java.util.Collection)\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">pause</a> this <code class=\"language-text\">TopicPartition</code>, so that subsequent <code class=\"language-text\">poll</code>s <strong>won't pull in</strong> more messages from it.\nWhen the queue is freed up again, it would <a href=\"https://kafka.apache.org/28/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html#resume(java.util.Collection)\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">resume</a> the same <code class=\"language-text\">TopicPartition</code> to get new messages starting from the next <code class=\"language-text\">poll</code>.\nThat's why we can keep <code class=\"language-text\">poll</code>ing. That's also why we use a short interval, so that we can \"resume\" faster.</li>\n</ul>\n<blockquote>\n<p><strong>pause</strong>(Collection&#x3C;<strong>TopicPartition</strong>> partitions)</p>\n<p>Suspend fetching from the requested partitions. Future calls to <strong>poll</strong>(Duration) will not return any records from these partitions until they have been resumed using <strong>resume</strong>(Collection).</p>\n</blockquote>\n<h3 id=\"executor\"><a href=\"#executor\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Executor</h3>\n<p><strong>Executor</strong> acts like a <a href=\"https://en.wikipedia.org/wiki/Thread_pool\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">thread pool</a>, where it maintains multiple workers to process the messages:</p>\n<ul>\n<li><strong>Executor</strong> and the number of workers is tunable to optimize for different workloads e.g CPU bound, I/O bound, etc.</li>\n<li>Each <strong>work queue</strong> is processed by one worker.</li>\n<li>One worker can be responsible for multiple <strong>work queue</strong>s.</li>\n<li>For each <strong>work queue</strong>, the worker processes its messages one by one.</li>\n</ul>\n<p>With this setup, messages within one partition is processed <strong>in order</strong>, while messages from different partitions are processed <strong>in parallel</strong>.</p>\n<h3 id=\"offset-manager\"><a href=\"#offset-manager\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Offset Manager</h3>\n<p>Each message in Kafka is associated with an <strong>offset</strong> - an integer number denoting its position in the current partition.\nBy storing this number, we essentially provide a checkpoint for our consumer. If it fails and comes back, it knows from where to continue.\nAs such, it is vital for implementing various processing guarantees in Kafka:</p>\n<ul>\n<li>For <em>at-most-once</em>, we need to save <code class=\"language-text\">$offset + 1</code> before processing <code class=\"language-text\">$offset</code>. If our consumer fails before successfully process <code class=\"language-text\">$offset</code> and restarts, it will continue from <code class=\"language-text\">$offset + 1</code> and not reprocess <code class=\"language-text\">$offset</code>.</li>\n<li>For <em>at-least-once</em>, we need to successfully process <code class=\"language-text\">$offset</code> before saving <code class=\"language-text\">$offset + 1</code>. If our consumer fails before saving <code class=\"language-text\">$offset + 1</code> and restarts, it will continue from and reprocess <code class=\"language-text\">$offset</code>.</li>\n<li>For <em>exactly-once</em> using an external <a href=\"https://kafka.apache.org/28/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html#rebalancecallback\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">transactional storage</a> - we need to process <code class=\"language-text\">$offset</code> and save <code class=\"language-text\">$offset + 1</code> within one transaction and roll back if anything goes wrong.</li>\n</ul>\n<p>With that in mind, we have <strong>Offset Manager</strong> providing a consistent interface for other components to work with these saved offsets:</p>\n<ul>\n<li>If we store offsets within Kafka, it is responsible for <strong>manually</strong> <a href=\"https://kafka.apache.org/28/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html#commitSync()\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">committing offsets</a>.</li>\n<li>If we decide to manage offsets using an external storage, it is responsible for retrieving from and saving into that storage.</li>\n<li>It allows <strong>Poller</strong> and <strong>Executor</strong> to save offsets either <strong>synchronously</strong> or <strong>asynchronously</strong> - in <a href=\"https://en.wikipedia.org/wiki/Fire-and-forget\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">fire and forget</a> fashion.</li>\n<li><strong>Offset Manager</strong> storing behavior can be configured: in <strong>batched</strong>, <strong>recurring</strong> with a timer, etc...</li>\n</ul>\n<p>What about Kafka's <a href=\"https://docs.confluent.io/platform/current/installation/configuration/consumer-configs.html#consumerconfigs_enable.auto.commit\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">auto commit</a>? Confluent <a href=\"https://docs.confluent.io/platform/current/clients/consumer.html#offset-management\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">claims</a> that:</p>\n<blockquote>\n<p>Using auto-commit gives you “at least once” delivery: Kafka guarantees that no messages will be missed, but duplicates are possible.</p>\n</blockquote>\n<p>This is true for delivery, however, it doesn't provide any guarantee for processing:</p>\n<ul>\n<li>It's not <em>at-most-once</em>: If some messages are successfully processed, and our consumer crashes before the next auto commit event, these messages are reprocessed.</li>\n<li>It's not <em>at-least-once</em>: If auto commit kicks in, and our consumer crashes right afterward, some messages are lost.</li>\n</ul>\n<p>Due to this, we always set <code class=\"language-text\">enable.auto.commit</code> to <code class=\"language-text\">false</code> and have <strong>Offset Manager</strong> manage offsets manually.</p>\n<h2 id=\"achieving-processing-guarantees\"><a href=\"#achieving-processing-guarantees\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Achieving processing guarantees</h2>\n<p>Let's go through a few example use cases to see how the components work together to satisfy different processing guarantees.</p>\n<h3 id=\"at-most-once-offsets-managed-by-kafka\"><a href=\"#at-most-once-offsets-managed-by-kafka\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>At-most-once, offsets managed by Kafka</h3>\n<p><img class=\"g-image g-image--lazy g-image--loading\" src=\"data:image/svg+xml,%3csvg fill='none' viewBox='0 0 693 411' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-f860433ba017d383f85c870c2afdb3cb'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-f860433ba017d383f85c870c2afdb3cb)' width='693' height='411' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAmCAYAAAB0xJ2ZAAAACXBIWXMAAAsSAAALEgHS3X78AAAGKUlEQVRo3t2ah08dRxDG779NFMdJZEVKYjuOLBQlBAKyBEIkSIQmJASIZpoNpvfeMcam92JMx9gTfivN077z3Wt0Vhpur%2b3tfjvzTXk4YrXPnz8Hjol/Jcj9e/dk%2bs2bL%2b7fpeZ4AXBwcCAJ8fES9/Sp9Pb2Sn1dvXR2dJh7nz59Ms/dFTAc94WPHz%2baY1lJqTz86Wfp6e6Wb776Wh7/8lDev38fAOqugBAEALtLe/v2rVl8/B9/yg/3v5OszEwpLysL0hTbXG4zEJ4AtLW2ym%2b/PpHy0jKz%2b0ODgzI6MiKtZ9c/fPhwp4D4ggMUhIx//pXvv70vOdnZBoQnjx7LxsaG7OzsyMrKihweHnoC4QXMrQJAJ5yXmyu/x8XJu3fvJPnvJMn%2bLyvw3MnJiayvrxuhb4Nnk%2bRt0ApPL7C/vy%2bPzkjvxwcPpLenJ%2bieaggNLVhdXZWtrS3PwW%2bDSfiawOvJ11JdVSVjY2Nh7R1eaG9vl7a2NmlsbJQXL17IwsLCrXCbjtdFe5f7%2bvoC5261tvtDQ0NSU1NjgED29vaCALipROnLAaenp6YP8dF3q7QbjImJCWloaJDq6mqjBcvLy3J8fHzjidHxs12d5NLSUpAGRGrrLH5tbS0IQDdwkchlA%2bb43dCPspN%2bALgnqV7ANiEIFbe5vb0d9ULcGnfjAAilOV5ECRBHR0eGH3Z3d32FZ8lHroI3HL%2bF2wDYHBDJZPyAAEhAAABcKNrBgjmyYAWAe5ubm4Go8zJBCAkAAge4bThWFUYAAI/R3NxsiHN2dlZ6zmKN/v5%2b00dwvZgMHBKp9p0bAL9dYyJ%2b4EQLhAJQUVEh%2bfn5kp6eLnV1dVJ2lmilpKRISUmJpKamSvxZKj43N%2bfrga5EA0Aet5aXl2eSoPOQkQ0AJmU3UmxAQCvcLRIPdOEagODC%2bHh5eblUnUWDqCfnGtycRwMAgCMLn5%2bfN6k34w8PDxv1Z%2be17hANAV8IANrYkcLCQmlpaTEgcF5QUGBC3YsAgEalibHZ%2bampKaNtAwMDJppcXFy8Hg3Qo016th3Gao9eGkBj158/fy719fWGF2prawNaduUa4Bd42Lvg5SbDuUI3cUKC2sgkx8fHZXJy0ghegTjhWgBwT9QvDvCbjNf7blNhHADFz9ta5k7EEFJs9UBXGgdEGgn6hcBu0YUT7DQ1NZk0maoSQDA2R1u4hvDMVdQVnHCJSLhcIFzTognMbptSLPwR6XPRiBNuAl4A2AARuhLJdXd3m3iBI3ZdWVlpoj2ITeuH0U4ulsVHrQF2/E3sbSclNEjLKxfQI6zNQlk8/nxkZMS4OFxmR0eHUXsd6zJTXB2PGMZeB6anOYd9zjPUM52uri7jj3FHBCaoKokI7g9RDfAjNgDAdxMnTE9Pm50vLS01QAAM57YGXEazF0/%2bAHlCoqyDwIq4gnMEDkJ4hvU5/GGBtvvRxrXOzk7Pj6IVgBUqW9SKcSj%2buIjfFvQdiFOjSP0%2b5Tk7zMZc2XQaVW1Hoy5AADEtdwMMrEwUqOcqPAfSfDAS%2b/Xr22V0ux%2bNtthjMh87eUM709LSpLi4OPBsVlaWZGZmmj6a4LBIfdkuWKBOurP0ydc1jwcEd64eK8GFCqCiHQsbt0v0aENCQoJZMI3fPQEkOTk5EJM4uCgWzcO272XX4QQeYlDbhQEGIJy3EfmhYeQBJEUQ6Xl4Qn%2b5YpNGR0cNKUPEmAGR5uDgoDnX7Bbtd1gYakMmZqsPcXpubq48e/ZMcnJyjNprA%2bmZmRkDHJrAR5VZEfpcQ2MQva/lLkCHO0h%2bmAw8w/ewT%2b4BPqDrWPqejqtsrn02hPdevnxprrOZEDH5BeuDC6hWFxUVBf22yQY7XvYTrvrLB%2bEAJcNQkaCX4DUoflAIof/q1SuzM5ATk%2baaZo2Rjq/FG92EpKQkU3BRE87IyJDExMSgZCsIAF5SteajCDajfRWed9frrrvZm4iwQYDKrgMO58QlgO4LAEfUzo7HvYT7Xv8ocRkSzTd0E5UEMU%2b/zVFyJ0ZwLqLMFWuB9KJ%2bFPGKA9BegjDMCW4gKEMDCNNtondiTSJu0s9cOgcWjYZi86i%2bVp%2bpbGECeBy8jfIYbv9/p3fysHzGAR0AAAAASUVORK5CYII=' /%3e%3c/svg%3e\" width=\"693\" alt=\"At most once\" data-srcset=\"/assets/static/at-most-once.c19ed0b.4c803014b443847cb8b453ce2f5c503e.png 693w\" data-sizes=\"(max-width: 693px) 100vw, 693px\" data-src=\"/assets/static/at-most-once.c19ed0b.4c803014b443847cb8b453ce2f5c503e.png\"><noscript><img class=\"g-image g-image--lazy g-image--loaded\" src=\"/assets/static/at-most-once.c19ed0b.4c803014b443847cb8b453ce2f5c503e.png\" width=\"693\" alt=\"At most once\"></noscript></p>\n<p>For <em>at-most-once</em>, we just need to commit offsets <strong>before</strong> processing the messages.\nWe can do it right before processing each message. However, it doesn't give us a stronger guarantee while introducing more costs.\nTherefore, <strong>Poller</strong> is responsible for it. After each <code class=\"language-text\">poll</code>, it will tell <strong>Offset Manager</strong> to save these offsets and <strong>wait</strong> for a success acknowledgement from Kafka before queuing the messages for processing.</p>\n<p>Prior to a <strong>rebalance</strong> event, it just needs to send a <em>fire-and-forget</em> signal to <strong>Executor</strong> to stop processing. It then takes down the work queues and gets back to wait for <strong>rebalance</strong>.\nThe lost messages are those still sitting in the queues or in the middle of processing. If we want to optimize for fewer lost without affecting the duration of <strong>rebalance</strong>, we can use a smaller queue size.</p>\n<h3 id=\"at-least-once-offsets-managed-by-kafka\"><a href=\"#at-least-once-offsets-managed-by-kafka\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>At-least-once, offsets managed by Kafka</h3>\n<p><img class=\"g-image g-image--lazy g-image--loading\" src=\"data:image/svg+xml,%3csvg fill='none' viewBox='0 0 693 411' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-108d028107e7cc92511aa40197db049c'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-108d028107e7cc92511aa40197db049c)' width='693' height='411' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAmCAYAAAB0xJ2ZAAAACXBIWXMAAAsSAAALEgHS3X78AAAGbUlEQVRo3t2ZiU/dRhDG/d%2b2akpbRZXaJmmqCFUthYKQQIgWiRJASAkgrnCEI%2bG%2bz0C4gwj3HSDcCVN%2bq87TPsfmnaHASovtZ7Pe/eabb2bHjljt/Pw8cEz5I1kS7tyR2ZmZT%2b7fpuZ4AXB4eCjJSUmS%2bOiR9Pf3S1Njk3R3dZl7Hz9%2bNM/dFjAc9w9nZ2fmWFFWLvd%2b%2bFH6envlqy%2b%2blAc/3ZN3794FgLotIAQBgHVpb968MYtP%2bu13%2bS7hG8nLzZXKioogptjucpOB8ASgo71dfvn5oVSWVxjrjwwPy9joqLRf/L63t3ergPhEAxSEnL/%2blm%2b/TpD8x48NCA/vP5DNzU3Z3d2V1dVVOTo68gTCC5gbBYBOuLCgQH5NTJS5uTlJ%2bzNVHv%2bTF3ju9PRUNjY2TOfcBs8WyZvACs8ocHBwIPcvRO/7u3elv68v6J4yhAYL1tbWZHt723Pwm%2bASvi4wNTkltTU18vr165D%2bji50dnZKR0eHNDc3S319vSwuLt6IsOl4/WhbeWBgIHDtprV9PjIyInV1dQYI%2bvv374MAuK5C6asBHz58MOcIH%2bduSrvBmJiYkJcvX0ptba1hwcrKipycnFx7YXT8fFcnuby8HMSAcH2dxa%2bvrwcB6AYunP65AXP8buhLsaQfAO5JahSwXQhBJWzu7OxEvBA3464dAJcxx0soAeL4%2bNjow/7%2bvm/nWfYjV6Ebjt/CbQBsDQhnMn5AACQgAAAhFHawYI4sWAHg3tbWViDr/JwgXAoAHQ1w%2b3C0FKYDABGjtbXVCOf8/Lz0XeQag4OD5pxO6MVl0JBw2RczAH5WYyJ%2b4EQKhAJQVVUlRUVFkp2dLY2NjVJxsdHKyMiQsrIyyczMlKSLrfjbt299I9CVMADkCWuFhYVmExSLGNkA4FJ2Y4sNCLDC3cKJQHFnAJ0QxssrKyul5iIbhJ5ca3ITCwMAgCMLX1hYMFtvxn/16pWhP5bXukMkAhwXALRhkeLiYmlrazMgcP3kyROT6sYDABqVJsbG8tPT04ZtQ0NDJptcWlr6fxigR1v0bD%2bM1h%2b9GEDD6s%2bePZOmpiajC8%2bfPw%2bw7MoZ4Jd42FbwCpOhQqFbOBFBbewkx8fHZXJy0nSiAnmCNp71qzN8VgbYL3LnAX5AhUpnlUEASpy3WebeiNGJPtQbIkmho2FKXDLBUC/l/0l2WlpazDaZqhJAMDZHu%2btvgIQmIJLhvicadjihEPUCwG8PgFWhsP7GkcyOBaHstiuF26hSwwZ7e817qETpO3TnGs1mywk1gVCbIW2krg0NDSapIbPr6uoyYe0ybQjV7So1446OjsqLFy9MJ2qoePb29katD46df5N725sSFSKvvYAeiRKI1%2bh/VePh4WET4hA3UtqZmRkT7yPxVfczsIoQzKJZ7NTUlAmf1B0AwBZWchh7Hbie7jnsa56BRU5PT4%2bJx4QjJgpVsSYLoysD/IRtdnZWqqurjfWxDOMBBBMkjyDnZ8KRFkntZ5kwoLLg7u5uAyzvZGwKMLiYAsX%2bAZehTsk6SKzIK7imo0F0nmF9Dn9YoB1%2btPEbL/Rq3FOltis/kQiUn6ZEKmzoA9ZEXDWL1Oo15Tk7zcY9MRKNuTuadQECiGm5G2BAlixQr%2bk8Q/zG2raw2cUQd/cLse5Sul1MuazY4lWCZ7FaeLGBycrKktLS0sA4eXl5kpuba85hgqP00Q8eWrDAqur7nLNf1308QLj36pH2yyJCtGPh43aJHgMlJyebBWtEAZC0tLRATuJgTRbNw4CgDaujCTzEoPaEAUOBi6VhNVwMP4aaiOnY2FjU4%2bmXK4zEOGyyiEa4AZkmAs217m5hv6NZFyHLpg95ekFBgaSnp0t%2bfr6hvo1sSUmJcQVEEuaE2/V5jnQmh1jil4gb/qruF87YPIPw8QULIDEO8ysvLzcRgvUBNPeYs/1tEwM76mcgpwCEyvh4CYtXWkGncLp%2bemfiT58%2bNdEHNSe8EUVgAbGd3ziGO7aOy/xZID01NdUUXNSFc3JyJCUlJWizFQQA/wTymrPrwO6X8Txs0DzhOjWMSMdAiDRWhwFck0dQcfIFgCO%2brtTz65rWRiuAsQhnqHExooqgpuReTcWdHMGJR5krmv%2bJ54cR243VOLAXV6LAgnuRNMEAMlRb6J1YrHJdPnPpHFg0DMXnob5WnxFZXICcRneXuAVa9C9XL91WSlUNlAAAAABJRU5ErkJggg==' /%3e%3c/svg%3e\" width=\"693\" alt=\"At least once\" data-srcset=\"/assets/static/at-least-once.c19ed0b.e24aee3b1e85cc3f6b638d30e4eb7de8.png 693w\" data-sizes=\"(max-width: 693px) 100vw, 693px\" data-src=\"/assets/static/at-least-once.c19ed0b.e24aee3b1e85cc3f6b638d30e4eb7de8.png\"><noscript><img class=\"g-image g-image--lazy g-image--loaded\" src=\"/assets/static/at-least-once.c19ed0b.e24aee3b1e85cc3f6b638d30e4eb7de8.png\" width=\"693\" alt=\"At least once\"></noscript></p>\n<p>For <em>at-least-once</em>, we just need to make sure offsets are only saved <strong>after</strong> the messages have been processed successfully.\nConsequently, if we were to process 10 messages, we wouldn't need to save offsets for all of them but only the last one.</p>\n<p>In this setup, <strong>Executor</strong> will emit signals to <strong>Offset Manager</strong> each time it completes processing for a message.\n<strong>Offset Manager</strong> keeps track of the latest offset for each partition - which in total is not that many - and decide <strong>when</strong> to commit them to Kafka.\nFor example, we can set <strong>Offset Manager</strong> to commit once every 5 seconds. This happens regardless of whether new messages are coming or not.\n<em>(Interestingly, this is important for older Kafka if we don't want to lose committed offsets in a low activity Kafka topic, see <a href=\"https://issues.apache.org/jira/browse/KAFKA-4682\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">KAFKA-4682</a>)</em>.</p>\n<p>Prior to a <strong>rebalance</strong> event, <strong>Poller</strong> set a hard <strong>deadline</strong> and notifies <strong>Executor</strong> to wrap up its <strong>in-flight</strong> processing and <strong>Offset Manager</strong> to follow up with a <strong>last</strong> commit.\nIf the deadline has passed, or <strong>Poller</strong> has received responses from others, it takes down the <strong>work queues</strong> and gets back to wait for <strong>rebalance</strong>.</p>\n<p>To optimize for fewer duplicated processing, we can:</p>\n<ul>\n<li>Use a <strong>looser</strong> deadline, allowing more time for \"wrapping up\". However, it also increases timing for <strong>rebalance</strong>.</li>\n<li>Set <strong>Offset Manager</strong> to commit more often.</li>\n</ul>\n<h3 id=\"exactly-once-offsets-managed-externally\"><a href=\"#exactly-once-offsets-managed-externally\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Exactly-once, offsets managed externally</h3>\n<p><img class=\"g-image g-image--lazy g-image--loading\" src=\"data:image/svg+xml,%3csvg fill='none' viewBox='0 0 693 411' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-b73808922731523ccfea2d215b46970c'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-b73808922731523ccfea2d215b46970c)' width='693' height='411' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAmCAYAAAB0xJ2ZAAAACXBIWXMAAAsSAAALEgHS3X78AAAG2ElEQVRo3s2ah09VdxTH73/bppa2MU3aamtjTNNSKMREQ2hJKAIxIUDYS8DFHoqCLEXZQxkOUFDw9H1%2b6SHnPe69bzJ%2bycmd73d/Z33P%2bD1PzPj8%2bfPhMffPHMk6d05mnj078vysjlTW5/lN8P79e8nJzpYrly/L8PCwdHZ0Sn9fn3t2cHBw5gTBenRNb968kZWVFVldXXW0trbmru09iOt3795FC4Dx6dMnd6yrqZULP/woQ4OD8tUXX8rFny7I69evz5wlWKtlLC8vy8ePHx0fu7u7sr297ZQG6T2ec827UQLgJuP58%2beO%2bezf/5Dvsr6RkuJiaairPyLts6J1ux40q2N/f1/u3r0rt27dkoGBAen734p1YAm%2bAujp7pZff7kk9bV1TvsjDx/K06dPo945LS37kY6RkRHHMGNiYkJaWloc8/fu3ZOOjg65f/%2b%2bdEd4W1hYOLSWIxigDBb9/Y98%2b3WWlN644YRw6eLPzr9OywXCvommX7586Vx0cXHR3dvc3HSMPouA%2bMbGhszPzzsajLj0q1evggWgHyovK5PfrlyRFy9eSP5feXLj3xJfkztJ5vFhABo/3tvbc9cfPnxwQMc1g3P8Hj9HMChUzyGdh3cQmm8U2NnZcaD3/fnzMjw05As2p%2bHrS0tLzqRbW1udeZdFlARe2Xdhcn193TEHIRA9WuIdhBPoAtNT09LS3Czj4%2bOhoHPSYDc1NSVdXV0O0Pr7%2bw/Xmyo4e343LdA9ePAg7Y9kEuWfPHniGL99%2b7Y8fvw4am1hQBlEgRiAKXGOqajvnCTzfgIH4WtqatwRRK%2burnbWkHELsJOBlLFSPo5QFhbiADH1YxAchN/a2nJr437GBWAXTGKRrgDSwQ4AGcYRQiZrgBMVgP0tc5GDhxH5Bm5H9jYzMxOFTUFWkjELiNUWArAYkMpH7O8wYWIw8RvtwjBH4rsKgGckL2rexxmGvXi%2bip%2bpAFJdgJ2T/Bv0BsQmJydlbm5OhiK5xsNIus05ROjFxwHg4w6/XlDY0XMWEg%2bdkxVAQ0OD3Lx5UwoLC12OXldXJ9euXXMIf/36dcmOlOKkrScRgbwwX71z546Ul5e7AiJTFmCrNQb5O0LAKmJHpiJQUhYAkVfz8fr6emmOZIOYJ9f4broWgAA4wjjFCqks84%2bOjjrzR/Pad8gUACcsAB1opLKy0iUZCIHriooK6enpyYgAGHSamBvNU2pjbZSz5Pnk/KdiAbag0GH9MFl/jA1V2oXRa7Te2NgonZ2dDhfa2toOrezELSD2I36ZYKLhKCxGay2upSuNCwociKhAqWs7NrYHeRy1iBeWqvrlAUGCitetYcAgZk49rr1Hv0IMIvpYYWUi6Tm2TDCeNZDZkdTMzs66BAfmtFOLhVnSeyRDVKLkBJZxFZCldPIEL14hEiSAWI3wDuZLRqddWY6YMQyn2ktkPoT39u3bYym2vHgL8BNAUHZGQkPYbGpqcoBGWhtr3qlUg9rwpJ9HmJyennYNkUePHrnzdIDSs/k3UrZFiQKRXy1gzzFtFkijgpjOQglnvb29zu%2bD8CXR6lELI9Jn3IKmCD0B2mKEUe1dMMhhLB/UGVpz2GvewUI9JiYeE45ITEhC8FPCH6QWEKQZnsE8GoFxQhtxHUGwYBabjo%2bG/Ya16saHNjtxF1yOnoF2g8kruIboGkNaa3jaHLThRwf30GqQbzIhAgqr1cPqiDCz9zu3wGcBljWgUW2N62BdWKFNsym8ULqGZE%2bzLiZFYtyEEAxoTBao1xDv4Bb05CwwxaKyPY/HvAXSRATlFwpZF1ZsBYB1FBQUuNaZ/qakpESKi4vdOZbgwaRuKsKY7qfhS%2br7nKNxreMRhGZsqQBb2AarfZ7MfMowVmldJCcnxzGsLoJA8vPzHW9uY4RsDKZ5WXd%2b1DzABF5iUhvGEIYKLp1BFki0oNcPbrCFlc5AMfCAksAecAhswg3INIkaXGt1i/V7mnVRidnaHzBj4%2bHq1atSWlrqTMxKtqqq6nDr2W47h5G%2bq40PFqiRY2xszB0xSxYGeNnfhM2J77ODRVRAOayvtrbW1Re6M8Qz1mzdFgV7dl9dBRAv4%2bMjMK9mpdtOYWTfa29vd4vTfIFKEGAiipBHgDswl%2bj8mlazfhiE8vLyXMNFXbioqEhyc3Ojiq0oAfAjTEjjbuyilXgfa4hNcs7CQIkQCgKk0ToWwDWlPB2nQAFwxNc1Hw8ints/SqRCQfl8UH6faMaIEhUEwbUgS1Zwx828TLS5kk1okmEqkfmtG6tysF5cjIwUlyMpwwIAXgv0XqpFxGntFsfbPsdC8XmsSLvPdLZwAbBFd5NxC3DmP5Ieyzh%2bJwXRAAAAAElFTkSuQmCC' /%3e%3c/svg%3e\" width=\"693\" alt=\"Exactly once\" data-srcset=\"/assets/static/exactly-once.c19ed0b.ee2808cf87a3ed8198eed48ab6d53d86.png 693w\" data-sizes=\"(max-width: 693px) 100vw, 693px\" data-src=\"/assets/static/exactly-once.c19ed0b.ee2808cf87a3ed8198eed48ab6d53d86.png\"><noscript><img class=\"g-image g-image--lazy g-image--loaded\" src=\"/assets/static/exactly-once.c19ed0b.ee2808cf87a3ed8198eed48ab6d53d86.png\" width=\"693\" alt=\"Exactly once\"></noscript></p>\n<p>In this case, offset saving and message processing needs to happen within one transaction. This means <strong>Executor</strong> and <strong>Offset Manager</strong> working closely together using <strong>synchronous</strong> calls to make it happen.</p>\n<p>Following a <strong>rebalance</strong> event, <strong>Poller</strong> asks <strong>Offset Manager</strong> for the saved offsets of current assignments. It then <a href=\"https://kafka.apache.org/28/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html#seek(org.apache.kafka.common.TopicPartition,long)\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">seek</a>s to restore the saved positions before resuming to <code class=\"language-text\">poll</code>.</p>\n<blockquote>\n<p>public void <strong>seek</strong>(TopicPartition partition, long offset)</p>\n<p>Overrides the fetch offsets that the consumer will use on the next poll(timeout).</p>\n</blockquote>\n<p>Prior to a <strong>rebalance</strong> event, <strong>Poller</strong> notifies <strong>Executor</strong> and waits for its response.\n<strong>Executor</strong> rolls back its <strong>in-flight</strong> transactions and return to <strong>Poller</strong>.\n<strong>Poller</strong> then takes down the work queues and gets back to wait for <strong>rebalance</strong>.</p>\n<h2 id=\"conclusion\"><a href=\"#conclusion\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Conclusion</h2>\n<p>We analyze the various issues with the <strong>loop-then-process</strong> loop and come up with a more proper model for understanding and implementing Kafka Consumer.\nThe downside is that it is much more complicated, and probably not easy for beginners. We blame this complexity on Kafka and its low level API.</p>\n<p>In practice, we probably won't do it ourselves but use a ready-made library that may or may not base on similar models: <a href=\"https://doc.akka.io/docs/alpakka-kafka/current/home.html\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Alpakka Kafka</a>, <a href=\"https://spring.io/projects/spring-kafka\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">Spring for Kafka</a>, <a href=\"https://github.com/zio/zio-kafka\" target=\"_blank\" rel=\"nofollow noopener noreferrer\">zio-kafka</a>, etc...\nEven then, the proposed model can be useful for evaluating these solutions or implementing new ones.</p>\n","description":"A better model to understand and implement Kafka Consumers, which also supports back pressure and parallel processing.","tags":[{"title":"kafka"},{"title":"concurrency"},{"title":"parallelism"}],"headings":[{"value":"Introduction","anchor":"#introduction","depth":2},{"value":"The problems with the poll-then-process loop","anchor":"#the-problems-with-the-poll-then-process-loop","depth":2},{"value":"A better model","anchor":"#a-better-model","depth":2},{"value":"Achieving processing guarantees","anchor":"#achieving-processing-guarantees","depth":2},{"value":"Conclusion","anchor":"#conclusion","depth":2}]}},"context":{}}