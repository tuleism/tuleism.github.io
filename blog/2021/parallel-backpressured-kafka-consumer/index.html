<!DOCTYPE html>
<html data-html-server-rendered="true" lang="en" data-vue-tag="%7B%22lang%22:%7B%22ssr%22:%22en%22%7D%7D">
  <head>
    <title>Parallel, Back-pressured Kafka Consumer | Random.nextBlog</title><meta name="gridsome:hash" content="25a5d663bc74a8a307f4df8ab380b824472878c6"><meta data-vue-tag="ssr" charset="utf-8"><meta data-vue-tag="ssr" name="generator" content="Gridsome v0.7.23"><meta data-vue-tag="ssr" data-key="viewport" name="viewport" content="width=device-width, initial-scale=1, viewport-fit=cover"><meta data-vue-tag="ssr" data-key="format-detection" name="format-detection" content="telephone=no"><meta data-vue-tag="ssr" name="theme-color" content="#10c186"><meta data-vue-tag="ssr" name="google-site-verification" content="cwS6wWeYJ-lTlEh9mPtc_UOGJjRptMvsO0nOQvqrzD4"><meta data-vue-tag="ssr" name="apple-mobile-web-app-status-bar-style" content="default"><meta data-vue-tag="ssr" name="author" content="Linh Nguyen"><meta data-vue-tag="ssr" name="copyright" content="Linh Nguyen, 2021. All rights reserved"><meta data-vue-tag="ssr" property="og:image" content="https://tuleism.github.io/logo-512.png"><meta data-vue-tag="ssr" name="twitter:card" content="summary"><meta data-vue-tag="ssr" name="twitter:site" content="@tuleism"><meta data-vue-tag="ssr" name="twitter:image" content="https://tuleism.github.io/logo-512.png"><meta data-vue-tag="ssr" data-key="description" name="description" content="A better model to understand and implement Kafka Consumers, which also supports back pressure and parallel processing."><meta data-vue-tag="ssr" property="og:type" content="article"><meta data-vue-tag="ssr" property="og:description" content="A better model to understand and implement Kafka Consumers, which also supports back pressure and parallel processing."><meta data-vue-tag="ssr" property="og:site_name" content="Random.nextBlog"><meta data-vue-tag="ssr" property="og:title" content="Parallel, Back-pressured Kafka Consumer"><meta data-vue-tag="ssr" property="og:url" content="https://tuleism.github.io/blog/2021/parallel-backpressured-kafka-consumer/"><meta data-vue-tag="ssr" name="article:author" content="Linh Nguyen"><meta data-vue-tag="ssr" name="article:published_time" content="2021-09-14"><meta data-vue-tag="ssr" name="twitter:title" content="Parallel, Back-pressured Kafka Consumer"><meta data-vue-tag="ssr" name="twitter:description" content="A better model to understand and implement Kafka Consumers, which also supports back pressure and parallel processing."><meta data-vue-tag="ssr" name="twitter:url" content="https://tuleism.github.io/blog/2021/parallel-backpressured-kafka-consumer/"><meta data-vue-tag="ssr" name="article:tag" content="kafka"><meta data-vue-tag="ssr" name="article:tag" content="concurrency"><meta data-vue-tag="ssr" name="article:tag" content="parallelism"><link data-vue-tag="ssr" rel="icon" href="data:,"><link data-vue-tag="ssr" rel="icon" type="image/png" sizes="16x16" href="/assets/static/favicon.ce0531f.3229556683113e2c3373be22d950d386.png"><link data-vue-tag="ssr" rel="icon" type="image/png" sizes="32x32" href="/assets/static/favicon.ac8d93a.3229556683113e2c3373be22d950d386.png"><link data-vue-tag="ssr" rel="icon" type="image/png" sizes="96x96" href="/assets/static/favicon.b9532cc.3229556683113e2c3373be22d950d386.png"><link data-vue-tag="ssr" rel="apple-touch-icon" type="image/png" sizes="76x76" href="/assets/static/favicon.f22e9f3.3229556683113e2c3373be22d950d386.png"><link data-vue-tag="ssr" rel="apple-touch-icon" type="image/png" sizes="152x152" href="/assets/static/favicon.62d22cb.3229556683113e2c3373be22d950d386.png"><link data-vue-tag="ssr" rel="apple-touch-icon" type="image/png" sizes="120x120" href="/assets/static/favicon.1539b60.3229556683113e2c3373be22d950d386.png"><link data-vue-tag="ssr" rel="apple-touch-icon" type="image/png" sizes="167x167" href="/assets/static/favicon.dc0cdc5.3229556683113e2c3373be22d950d386.png"><link data-vue-tag="ssr" rel="apple-touch-icon" type="image/png" sizes="180x180" href="/assets/static/favicon.7b22250.3229556683113e2c3373be22d950d386.png"><link data-vue-tag="ssr" rel="manifest" href="/manifest.json"><link rel="preload" href="/assets/css/0.styles.996c65bd.css" as="style"><link rel="preload" href="/assets/js/app.185c96bb.js" as="script"><link rel="preload" href="/assets/js/page--src--templates--doc-vue.fff5180d.js" as="script"><link rel="prefetch" href="/assets/js/page--src--pages--404-vue.b8c718d9.js"><link rel="prefetch" href="/assets/js/page--src--pages--about-vue.2b6aa2f3.js"><link rel="prefetch" href="/assets/js/page--src--pages--index-vue.dc2a659f.js"><link rel="stylesheet" href="/assets/css/0.styles.996c65bd.css"><noscript data-vue-tag="ssr"><style>.g-image--loading{display:none;}</style></noscript>
  </head>
  <body >
    <div data-server-rendered="true" id="app" class="site" data-v-0431039b data-v-11d90a72><header class="header" data-v-1c71a4d0 data-v-0431039b><a href="/" title="Back to home" class="blog-name active" data-v-dd29784a data-v-1c71a4d0><span data-v-dd29784a>tuleisM &gt;&gt;= Random.nextBlog</span></a><nav class="nav" data-v-1c71a4d0><button id="themeSwitch" aria-label="Switch theme between light and dark" data-v-385ac126 data-v-1c71a4d0><!----><!----></button><button aria-label="Toggle the sidebar" class="toggle" data-v-def1a688 data-v-1c71a4d0><svg xmlns="http://www.w3.org/2000/svg" width="24px" height="24px" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="open feather feather-menu" data-v-def1a688 data-v-def1a688><line x1="3" y1="12" x2="21" y2="12" data-v-def1a688></line><line x1="3" y1="6" x2="21" y2="6" data-v-def1a688></line><line x1="3" y1="18" x2="21" y2="18" data-v-def1a688></line></svg><svg xmlns="http://www.w3.org/2000/svg" width="24px" height="24px" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="close feather feather-x" style="display:none;" data-v-def1a688 data-v-def1a688><line x1="18" y1="6" x2="6" y2="18" data-v-def1a688></line><line x1="6" y1="6" x2="18" y2="18" data-v-def1a688></line></svg></button></nav></header><aside class="sidebar" data-v-34cfceb7 data-v-0431039b><nav data-v-34cfceb7><hr class="dashed" data-v-34cfceb7><div class="icons" data-v-34cfceb7><a href="/" title="Blog" class="topic" data-v-34cfceb7>blog</a><a href="/about/" title="About Me" class="topic" data-v-34cfceb7><svg xmlns="http://www.w3.org/2000/svg" width="24px" height="24px" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon feather feather-info" data-v-34cfceb7><circle cx="12" cy="12" r="10" data-v-34cfceb7></circle><line x1="12" y1="16" x2="12" y2="12" data-v-34cfceb7></line><line x1="12" y1="8" x2="12.01" y2="8" data-v-34cfceb7></line></svg></a><a title="GitHub @tuleism" href="https://github.com/tuleism" target="_blank" rel="noopener" class="topic" data-v-34cfceb7 data-v-34cfceb7><svg xmlns="http://www.w3.org/2000/svg" width="24px" height="24px" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon feather feather-github" data-v-34cfceb7 data-v-34cfceb7><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22" data-v-34cfceb7 data-v-34cfceb7></path></svg></a><a title="LinkedIn @tuleism" href="https://www.linkedin.com/in/tuleism" target="_blank" rel="noopener" class="topic" data-v-34cfceb7 data-v-34cfceb7><svg xmlns="http://www.w3.org/2000/svg" width="24px" height="24px" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon feather feather-linkedin" data-v-34cfceb7 data-v-34cfceb7><path d="M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z" data-v-34cfceb7 data-v-34cfceb7></path><rect x="2" y="9" width="4" height="12" data-v-34cfceb7 data-v-34cfceb7></rect><circle cx="4" cy="4" r="2" data-v-34cfceb7 data-v-34cfceb7></circle></svg></a><a title="Twitter @tuleism" href="https://www.twitter.com/tuleism" target="_blank" rel="noopener" class="topic" data-v-34cfceb7 data-v-34cfceb7><svg xmlns="http://www.w3.org/2000/svg" width="24px" height="24px" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon feather feather-twitter" data-v-34cfceb7 data-v-34cfceb7><path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z" data-v-34cfceb7 data-v-34cfceb7></path></svg></a><a title="Instagram @randomphotohereandthere" href="https://www.instagram.com/randomphotohereandthere" target="_blank" rel="noopener" class="topic" data-v-34cfceb7 data-v-34cfceb7><svg xmlns="http://www.w3.org/2000/svg" width="24px" height="24px" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon feather feather-instagram" data-v-34cfceb7 data-v-34cfceb7><rect x="2" y="2" width="20" height="20" rx="5" ry="5" data-v-34cfceb7 data-v-34cfceb7></rect><path d="M16 11.37A4 4 0 1 1 12.63 8 4 4 0 0 1 16 11.37z" data-v-34cfceb7 data-v-34cfceb7></path><line x1="17.5" y1="6.5" x2="17.51" y2="6.5" data-v-34cfceb7 data-v-34cfceb7></line></svg></a><a title="Contact Me" href="mailto:tuleism@gmail.com" class="topic" data-v-34cfceb7 data-v-34cfceb7><svg xmlns="http://www.w3.org/2000/svg" width="24px" height="24px" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon feather feather-mail" data-v-34cfceb7 data-v-34cfceb7><path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z" data-v-34cfceb7 data-v-34cfceb7></path><polyline points="22,6 12,13 2,6" data-v-34cfceb7 data-v-34cfceb7></polyline></svg></a></div><hr class="dashed" data-v-34cfceb7><h3 class="section-title" data-v-34cfceb7>Table of Contents</h3><ul data-v-34cfceb7><li data-v-34cfceb7><a href="/blog/2021/parallel-backpressured-kafka-consumer/#introduction" class="sub-topic" data-v-34cfceb7>Introduction</a></li><li data-v-34cfceb7><a href="/blog/2021/parallel-backpressured-kafka-consumer/#the-problems-with-the-poll-then-process-loop" class="sub-topic" data-v-34cfceb7>The problems with the poll-then-process loop</a></li><li data-v-34cfceb7><a href="/blog/2021/parallel-backpressured-kafka-consumer/#a-better-model" class="sub-topic" data-v-34cfceb7>A better model</a></li><li data-v-34cfceb7><a href="/blog/2021/parallel-backpressured-kafka-consumer/#achieving-processing-guarantees" class="sub-topic" data-v-34cfceb7>Achieving processing guarantees</a></li><li data-v-34cfceb7><a href="/blog/2021/parallel-backpressured-kafka-consumer/#conclusion" class="sub-topic" data-v-34cfceb7>Conclusion</a></li></ul></nav></aside><main class="main" data-v-0431039b><div data-v-0431039b data-v-11d90a72><span class="date" data-v-0431039b data-v-11d90a72>Posted 14 Sep 2021 by </span><a href="/about/" title="About Me" class="topic" data-v-11d90a72>Linh Nguyen</a></div><h1 data-v-0431039b data-v-11d90a72>
    Parallel, Back-pressured Kafka Consumer
  </h1><div class="markdown" data-v-0431039b data-v-11d90a72><h2 id="introduction"><a href="#introduction" aria-hidden="true"><span class="icon icon-link"></span></a>Introduction</h2>
<p><a href="https://www.confluent.io/learn/kafka-tutorial/" target="_blank" rel="nofollow noopener noreferrer">Almost</a> <a href="http://cloudurable.com/blog/kafka-tutorial-kafka-consumer/index.html" target="_blank" rel="nofollow noopener noreferrer">every</a> <a href="https://www.oreilly.com/library/view/kafka-the-definitive/9781491936153/ch04.html" target="_blank" rel="nofollow noopener noreferrer">Kafka Consumer tutorial</a> structure their code like this:</p>
<div class="gridsome-highlight" data-language="java"><pre class="language-java"><code class="language-java"><span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">Payment</span><span class="token punctuation">></span></span> consumer <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">KafkaConsumer</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token punctuation">></span></span><span class="token punctuation">(</span>props<span class="token punctuation">)</span>
<span class="token comment">// Subscribe to Kafka topics</span>
consumer<span class="token punctuation">.</span><span class="token function">subscribe</span><span class="token punctuation">(</span>topics<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">while</span> <span class="token punctuation">(</span><span class="token boolean">true</span><span class="token punctuation">)</span> <span class="token punctuation">{</span>
    <span class="token comment">// Poll Kafka for new messages</span>
    <span class="token class-name">ConsumerRecords</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">></span></span> records <span class="token operator">=</span> consumer<span class="token punctuation">.</span><span class="token function">poll</span><span class="token punctuation">(</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// Processing logic</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span><span class="token class-name">ConsumerRecord</span><span class="token generics"><span class="token punctuation">&lt;</span><span class="token class-name">String</span><span class="token punctuation">,</span> <span class="token class-name">String</span><span class="token punctuation">></span></span> <span class="token keyword">record</span> <span class="token operator">:</span> records<span class="token punctuation">)</span> <span class="token punctuation">{</span>
        <span class="token function">doSomething</span><span class="token punctuation">(</span><span class="token keyword">record</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
  <span class="token punctuation">}</span>
<span class="token punctuation">}</span></code></pre></div>
<p>Basically we set up our <a href="https://javadoc.io/doc/org.apache.kafka/kafka-clients/latest/org/apache/kafka/clients/consumer/KafkaConsumer.html" target="_blank" rel="nofollow noopener noreferrer">Kafka Consumer</a>, <code class="language-inline-text">subscribe</code> it to some <a href="https://dattell.com/data-architecture-blog/what-is-a-kafka-topic/" target="_blank" rel="nofollow noopener noreferrer">Kafka topics</a> and then go into an infinite loop where, on each iteration, we <code class="language-inline-text">poll</code> some messages from these topics and process them one by one.
We can call this the <strong>poll-then-process loop</strong>.</p>
<p>This is fairly simple, easy to put into practice, and people may have been using it in production without any issue.
However, there are various problems with this model, which we're going into more details in the next section.</p>
<h2 id="the-problems-with-the-poll-then-process-loop"><a href="#the-problems-with-the-poll-then-process-loop" aria-hidden="true"><span class="icon icon-link"></span></a>The problems with the poll-then-process loop</h2>
<h3 id="1-it-is-not-the-expected-way-to-poll"><a href="#1-it-is-not-the-expected-way-to-poll" aria-hidden="true"><span class="icon icon-link"></span></a>1. It is not the "expected" way to poll</h3>
<p>Looking at the code above, we developers might think that <code class="language-inline-text">poll</code> acts as a way to signal <strong>demand</strong> to Kafka.
Our consumer only <code class="language-inline-text">poll</code>s to pull in more messages when it has finished working on previous ones.
If its processing rate is slow, Kafka would act as the <strong>shock absorber</strong>, ensuring we don't lose any message even when the producing rate is much higher.</p>
<p>On the other hand, when processing rate is slow, the <strong>interval</strong> between consecutive <code class="language-inline-text">poll</code>s also <strong>increases</strong>.
This is problematic since there is a default (5 minutes) upper bound on it with the <a href="https://docs.confluent.io/platform/current/installation/configuration/consumer-configs.html#consumerconfigs_max.poll.interval.ms" target="_blank" rel="nofollow noopener noreferrer">max.poll.interval.ms</a> configuration:</p>
<blockquote>
<p><strong>max.poll.interval.ms</strong></p>
<p>The maximum delay between invocations of poll() when using consumer group management. This places an upper bound on the amount of time that the consumer can be idle before fetching more records. If poll() is not called before expiration of this timeout, then the consumer is considered failed and the group will rebalance in order to reassign the partitions to another member. </p>
</blockquote>
<p>In other words, if our consumer doesn't call <code class="language-inline-text">poll</code> at least once every <code class="language-inline-text">max.poll.interval.ms</code>, to Kafka, it's as good as dead.
When this happens, Kafka follows up with a <a href="https://medium.com/streamthoughts/apache-kafka-rebalance-protocol-or-the-magic-behind-your-streams-applications-e94baf68e4f2" target="_blank" rel="nofollow noopener noreferrer">rebalance</a> process to distribute the current work of the dead consumer to the rest of its <a href="https://docs.confluent.io/platform/current/clients/consumer.html#consumer-groups" target="_blank" rel="nofollow noopener noreferrer">consumer group</a>.
This introduces more overhead and delay into an already slow processing rate.</p>
<p>Worse yet, if the processing causes slowness in one consumer, chances are, it would cause the same problem for other consumers taking over its work.
Moreover, the presumed dead consumer can also cause <strong>rebalance</strong> when it attempts to rejoin the group on its next poll (remember it's an <em>infinite</em> loop!).
Both of these makes <strong>rebalance</strong> happen again and again, slowing consumption even more.</p>
<p>Now, there is another configuration which can help with this situation:</p>
<blockquote>
<p><strong>max.poll.records</strong></p>
<p>The maximum number of records returned in a single call to poll(). Note, that max.poll.records does not impact the underlying fetching behavior. The consumer will cache the records from each fetch request and returns them incrementally from each poll.</p>
</blockquote>
<p>With this set to a lower value, our consumer will process fewer messages per <code class="language-inline-text">poll</code>. Thus, the <code class="language-inline-text">poll</code> interval will decrease.
Alternatively, we can also increase <code class="language-inline-text">max.poll.interval.ms</code> to a bigger value. This should solve the problem temporarily if we can't move away from the <strong>poll-then-process</strong> loop.
Nevertheless, it is not ideal.</p>
<p>Firstly, these configurations are set when we start our consumers, but whether they work or not depends on the messages or the applications.
We may set them specifically for each application, but in the end, we're playing a <strong>guessing game</strong> and pray that we're lucky.</p>
<p>Secondly, in the worst case, it may take <strong>twice</strong> the <code class="language-inline-text">max.poll.interval.ms</code> duration for the <strong>rebalance</strong> process to start:</p>
<ol>
<li>Kafka has to wait <code class="language-inline-text">max.poll.interval.ms</code> to <strong>detect</strong> that our consumer is not <code class="language-inline-text">poll</code>ing anymore.</li>
<li>When Kafka decides to <strong>rebalance</strong> the group, other consumers are only <strong>made aware</strong> of this decision on their <strong>next</strong> <code class="language-inline-text">poll</code>.</li>
</ol>
<p>We never want <strong>rebalance</strong> to take even more time, so setting a higher <code class="language-inline-text">max.poll.interval.ms</code> is not great.</p>
<p>Finally, these configurations implies that our consumer is "expected" to <code class="language-inline-text">poll</code> frequently, at least once every <code class="language-inline-text">max.poll.interval.ms</code>, no matter what kind of processing it is doing.
By not incorporating this expectation, the <strong>poll-then-process</strong> loop is not only <strong>misleading</strong> to developers but also doomed to fail.</p>
<h3 id="2-message-processing-is-synchronous"><a href="#2-message-processing-is-synchronous" aria-hidden="true"><span class="icon icon-link"></span></a>2. Message processing is synchronous</h3>
<p>Kafka only guarantees the <strong>order</strong> of messages <strong>within one partition</strong>. Messages from different partitions are unrelated and can be processed in parallel.
That's why in Kafka, the <strong>number of partition</strong> in a topic is the unit of <strong>parallelism</strong>.</p>
<p>In theory, we could easily achieve maximum parallelism by having <strong>as many</strong> consumers running as the number of partitions on a topic.
However, in reality, this is too much overhead, not to mention its impact on increasing the chance for <strong>rebalance</strong>, since there are more consumers that can come and go.</p>
<p>If we look at our <a href="#introduction">consumer code</a> again, it can subscribe to multiple topics and possibly receive messages from multiple partitions.
Yet, when it comes to processing these messages, it does so one by one. This is not optimal.</p>
<p>Now, assuming our processing logic is very simple, could we just use a <a href="https://en.wikipedia.org/wiki/Thread_pool" target="_blank" rel="nofollow noopener noreferrer">thread pool</a> to parallelize it?
For example, by submitting one processing task to the thread pool, for each message?</p>
<p>Well, kind of. It only works if we don't care about processing <strong>ordering</strong> and <strong>guarantees</strong> like <em>at-most-once</em>, <em>at-least-once</em>, etc. So it is not very useful in practice.</p>
<h2 id="a-better-model"><a href="#a-better-model" aria-hidden="true"><span class="icon icon-link"></span></a>A better model</h2>
<h3 id="overview"><a href="#overview" aria-hidden="true"><span class="icon icon-link"></span></a>Overview</h3>
<p>The many setbacks of the <strong>poll-then-process</strong> loop come from the fact that different concerns - <code class="language-inline-text">poll</code>ing, processing, offsets committing - are mixed together.
As a result, when we <strong>divide</strong> them into separated components, we end up with an improved model which supports <strong>parallel</strong> processing and <strong>back-pressure</strong> properly.
Each component is described in more details below.</p>
<p><img class="g-image g-image--lazy g-image--loading" src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 693 831' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-abb93788319a705f3cba6290ffe0c1b4'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-abb93788319a705f3cba6290ffe0c1b4)' width='693' height='831' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAABNCAYAAAAW92IAAAAACXBIWXMAAAsSAAALEgHS3X78AAAM5klEQVR42t2bh1cUSxbG55/d9e1bOXuOG9THe7rG9RkwZzErZsGAARUjIhgxYQKMiAoKEgXmbv1q5o41TU/o7hmcY51Tp6t7aqarbt373e/eqomJU%2bLxeKpdsXSpTP317/L06VPfz0uxhBlfzO8HhoaGZMmfi2Xef%2bdIc1OzXKyvl%2bsNDYk%2b43Hbr6RkEY%2bnxv7161fp7OyU9%2b/f29rV1WXv3WdU7r98%2bZIuAMrY6Ki9njxxQmb8%2bz9y5/Zt%2bfWXX6R8xkzp6e5OCYr3lYQQkoNQATCx4eFhGTXzGBkZsQIZHx%2b3lWd8xnP6I4g0AdCJ0tHeITOnz5A//7dI/lFWJtu2bpWa6urUS1wN%2bGGCcF/saACTGhsbS3W7du2anD17Vm7cuGHb7mcfPnzwFwDq/kf571J74qRM%2bctfpeXeXXnU%2blRaPon0D49nGkPxBOF9iU%2b1PZ49k87Tp227o63NTryurk4uX74s58%2bft1eE8Pz585SwJmCACmHrlkopMyC4e9cu%2bduUKUYg5fKx%2b7MMGAv5NBCX4VH/xfATTEGF4FfMmOMfP4oxaul8/do%2b6uvtldem/cwI5aP5jDb15s2b9koBHyYIQFVpX1WVzJszVzo6OmT5sgrZWllpADAhnNGxuHweEltHkwphsDGtFmXyqK8BaGPIYgw5cc/VTCQ%2bOJhQazPZvr4%2ba%2b%2boO/PRti4u7UHT31cAFD78feZv8q9p/5QbjY1p5jHuzAot6Dbv7R2eHKAzOity6pRITY2IAWkxiyL37ye6JPsxzm4D1kwuW0UrEExGE3jS2mo9waNHjyZoh9cNDn4TaTRadfWlSH27GeMzkbae75oRCR%2b89oT9Xrggglu%2beDGhAR4gDM0DvGBIuXXrVgo5VQh%2bwHe/S6TWcKZrRghXTP0ylC6AUEDp90UWhMmfOSPS1CTy7Vua9n4fY341Iwao/aBOrgC8C6OPWg0G1b0QOf5E5KxZpM6v3/HB12PkC3hu%2b%2bpVA077zIvqjKrVixw4IGJQPwrixjJRSp3su3fvfAWQC6CZfM9gAijHxlNWGniF7Hd4PyhvxmKYDg7cuCLjk0HzN28i%2beFYLl4Ns8okAO%2bqer2ApdVJoOwbDs7V6R0H8Q342WsYF1lMAeRrtpT%2bkbh8MoIYMS50YKBf%2bvuzVOPGBsGhu3etzccdf59me3pfSA2I%2b3BrLwgGBe5EO8HWuj5%2bsn4aVwtPp811YGDAtqm0u3t65AtuL8ny4gVnVnkIgAoGjI6Ohgo507EsnmRf7%2bXx48dy/fp1efHihTHhN9LS0mLr27dv7ftgb58/f5YPxs7Hkh4pXoTJpwlgop9PtAkZMwknmCtPfIcA5IThF7sMxV63bp3hNafs/YoVK%2bTw4cOyfv16mTt3rs1DEH2OJP18sXIRGTUALkDgsM%2b4Ha5RkyKuSbkFdb9oCM1tE3Z7C31V%2b4ouANf18FJW6tixY3Ly5ElLhqCPg0m%2bHQ/BulwBIFxNXLx8%2bVLu3LljGO19efXqlTUB1TqitUkXAOWCoZoHDMm4cuWKFQKh5P79%2bw0PuRpZAEyQctcgPL/N5MGCekNsaGMS7e3tP0YD9KoZE1aKoIF72t88tDPI5L0aYOONJ0%2bktrbWxulo2rlz56Snpyf1vUnVgIlUd%2bKA/dxkrkl7%2bzMpLZgV6P/w4UNbacMDMgkgHjLgCawB3hXzEqEgk/cOmt8j6eoK1e/78AG0L5eXKrgXCMsEMwnQfQbSY9%2b9vb0WC6j4frfyPq54hwcPHqSl5YshiFiuQCSXALINiDZZWGV%2bbkIy3wL%2bKEX2mqLfeyOFw34lkwCyrTj9UXMGzcT9tCFINEgBgHGdXvPxw5lAGsAAqYANA0b1tHrTzJkknQqBk79BZcCZJh7FnFQjGLMfODNWnYf2o%2bq4aOvi8Fsx8uVKeCAluCHAh/rJcHHVgEwro6vDD7JCbtwQdYWymZe%2b09UwddskcRg7lVgDTKHNc3CHrDBt%2bsb4QH/MW7Df5uZm38F51dy17yCrHXTPzysIxRhWE3BlPm6BxUKw9DsAK4vOnKkxZWZ0IAJDMlQ0AfVnc4Ef5Z7n9EFysETULNPgiuGzs/0%2bi8FYNdZQSr9z507Zu3dvKqiqrq6WTZs2pYA5JQAe8GWNy/kQ6WoOXWN3VhwBKGMLCmrFqhpYKXfgGSu8atUqWb16tRUQhSh04cKFdvzML8Yq0xH1oWohIOHHWHENgly1g8WVWmGRNIkLzSbAIn4h2uSeFH9DQ4ONbRCW1QA68yUAkMlquXfvnmzfvl0qKirs1WVlaMLRo0fTNIO2agg/jjAViWn79eWeNp8H%2bZ63L89ZUYI45sJqnzlzxoI7fdEG4g3yDW44zu/G3BVXAbjuBTvSe3fnCGTVz3Xbiau37fcsV98w32NszAEBoNEkVpYvX55S/aqqKpk/f35aLGIFoJNCsoqg2egsBUHRv9QKC6MCQO2PHDmS8lCNjY02ueOabpoAdE8NUERNuCIt8nfK0fV5qQGgHwgqucu285UygUwc37sxks0//8jiCsDlAdg97pqUHgkY8g0sqOs6Y9mCiExUuJAkp5ACYJyouFJx1J6EKxVQPHTokCVBaAAaMuGESCE2RkpBCLo9DlZhBqw%2brk/xi0VVBhzLFISonei%2bQKmterbNHG/BXarX8vaJ5bLr7uTJsFKz%2byARJFrhkjwFwrR8gPslOpOJQWoQIrSAlLWGyME2ReIF8Rj5701%2b74%2bNk4Ei60zOkcgQNqiB3wQBqNq3tbXJnj17rC89ffq0zdwCIJquDpsSL1REmK8AmpqarO2D/rBEgiUYbLdz3jGnCXgJT9jJE41pXO5Gl36Vz%2biDT2cVw2yPuX1Z0EuXLvl%2bnnFvUJGfQYOWetoyrPpCOjAjJgNlVSGoINw2FcHzXhBbiVfQ92t/3s2GqzsHXw3wi7ULFfVpeM1giM/JQBGb19TU2KCFNlcqFJYdIo08vQAWJrGqcU5OL%2bAVhkaJGpGFqYAOqswqcHKzrKzM8nLi9KlTp8qOHTtk8eLFMn36dIs9a9askcrKShvCwkNIYbnnB8K8WxfS6yFyCgDg07yAqmnQispjStgi1JQQG2Bl1deuXWvDVLSCsPv48eNWC9iLxBOB3LqXEPbdCNEVQCANKJQJwLs1dsezgM4gMwkLtILNUYQDUlMbksfzNQcQ1QTcTFHgnSGXCYYFQVVFCqsKJ4eiIgwSlZzhZdJUuIce0NSVDwOCmVJlkbbGoghAIzXMgUgNIZC2ImjhyAyRGllcNknfJI%2b/IQA3UTPpAsANFYLI6GYLA%2bEIzObNmy0Irly50h6VIXlJJZMDRpDNRXUxAfeYTpiCJwktAJCb1dC/mYSp4AinzlF5AK%2b8vNzaOWkqkB/QQyDz5s2zJgEA4iXoz9l%2bvAHmE%2bXdoUGQOICVyJa3y1YVP1BlCA72jgZs27bNTprV3rBhg3V9aALub8uWLdYjMAF3m1zzj0HfjQuPZALZ9vLzLWAAqgy7A%2bDQLNycVgIWVpqghStVqbibrQ7rgX44CGL/6gVQa9Qe93fw4EHL02GGGngRvJDF0YMSLosL825wJLIbLKQX0LiA3%2bYZTE9PhyEk3Zz1S9dPuhcAPArpBZgwYAfa4wE4IIn9k8PnnvbSpUvtFlZJeQEE4f7xMN/q9QIEOuoFoL9eL0AQhAfAQ0CI1AswAe%2bfH/Opkb0ApEU3STGFMBXV1a1rSA5eAJQH7ZctW5byAsQFrhfALPgek9fNzjDvLgkvgPqjyqi1Hn5qbW21q8uVlebKZzBC2ooXUU2gZL0AaE%2bqDS8A%2buMF8AYESVwRfEl4gSj7An5eoDf5p0bMC9vUNkRJvQBXPzcY5t0lIwCiOuySqx6v0YqGoO5U3RrXDFJJCSAKD2CFdVU1P6A5Aqq2%2bYw%2bfgKYdBPw/hs7igYwEUAQEkSqTckQGR/MgDYui%2be6kxPFBNx8ZGgBMBANKjSrGrTqRNT2p02bZgnQggULLCfAFeIaZ8%2bebYOjOXPmWNeoJqF5/LDvdpMxoaLBQoXDHFfjfwhMkBQYpGjWrFnWAxD/L1myxHoGMsXECJwthojhEpmAnl0IUhk3QtfMct4CKPQ%2boB6kRBCLFi2yRAfSs3HjRntsDWrMvRKh3bt3W9UHF6JGg9nmk1MDCnV6Q0EQtVQMQBjQXTAALSMkZsW5VyLkpsSKsb8YkyIXv4gM9oeKQ4ZYbfg/KXLID8%2b45/OoPCCfMqkCUCKEm1N3p4cWMA%2bN3OD86nm8GvBTCIBdW2gvlBfeT4DEypMd5hkgqPsCP5UA1ASwf5CfFDi2jgAQiv59DkHo/wh/SgHgzlhldoUQAK6PSbNPoBWh/LQmoCc5SZHDCziIgVskDwgYkgzRBIabEvtpBMAzGCamgPvjOZ4BN0ioTK5AQbHYGvB/YP5djBUQlXwAAAAASUVORK5CYII=' /%3e%3c/svg%3e" width="693" alt="Parallel Kafka Consumer" data-srcset="/assets/static/parallel-kafka-consumer.c19ed0b.28600783a4c9d1eb144a357c98e8292c.png 693w" data-sizes="(max-width: 693px) 100vw, 693px" data-src="/assets/static/parallel-kafka-consumer.c19ed0b.28600783a4c9d1eb144a357c98e8292c.png"><noscript><img class="g-image g-image--lazy g-image--loaded" src="/assets/static/parallel-kafka-consumer.c19ed0b.28600783a4c9d1eb144a357c98e8292c.png" width="693" alt="Parallel Kafka Consumer"></noscript></p>
<h3 id="work-queues"><a href="#work-queues" aria-hidden="true"><span class="icon icon-link"></span></a>Work Queues</h3>
<p>The <strong>Work Queues</strong> is the communication channel between <strong>Poller</strong> and <strong>Executor</strong>:</p>
<ul>
<li>There is a <em>one-to-one</em> mapping of assigned <a href="">TopicPartition</a>s to <strong>work queues</strong>.
After each <code class="language-inline-text">poll</code>, <strong>Poller</strong> pushes new messages from each partition into its corresponding work queue, <strong>preserving</strong> the original <strong>ordering</strong>.
Each work queue is also <strong>bounded</strong> with a configurable size. When full, it <strong>back-pressures</strong> <strong>Poller</strong> so that it can follow up with the appropriate actions.</li>
<li>The work queues are <strong>asynchronous</strong>, which <strong>decouples</strong> polling and message processing, allowing them to happen independently.
This is in contrast to the <strong>poll-then-process</strong> loop, where they are two sequential steps within a loop.</li>
</ul>
<h3 id="poller"><a href="#poller" aria-hidden="true"><span class="icon icon-link"></span></a>Poller</h3>
<p>In short, <strong>Poller</strong> encapsulates everything related to <code class="language-inline-text">poll</code> in Kafka:</p>
<ul>
<li>
<p>It watches out for <strong>rebalance</strong> events - e.g by registering a <a href="https://kafka.apache.org/28/javadoc/org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html" target="_blank" rel="nofollow noopener noreferrer">ConsumerRebalanceListener</a> - and coordinates other units to handle them.</p>
<ul>
<li>For each newly <a href="https://kafka.apache.org/28/javadoc/org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html#onPartitionsAssigned(java.util.Collection)" target="_blank" rel="nofollow noopener noreferrer">assigned</a> <code class="language-inline-text">TopicPartition</code>, it set up a new <strong>work queue</strong>.</li>
<li>For each <a href="https://kafka.apache.org/28/javadoc/org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html#onPartitionsRevoked(java.util.Collection)" target="_blank" rel="nofollow noopener noreferrer">revoked</a> (or <a href="https://kafka.apache.org/28/javadoc/org/apache/kafka/clients/consumer/ConsumerRebalanceListener.html#onPartitionsLost(java.util.Collection)" target="_blank" rel="nofollow noopener noreferrer">lost</a>) <code class="language-inline-text">TopicPartition</code>,
it commands both <strong>Executor</strong> and <strong>Offset Manager</strong> to <strong>wrap up</strong> related works and tears down the <strong>corresponding work queue</strong>.</li>
</ul>
</li>
<li>It <code class="language-inline-text">poll</code>s Kafka periodically using a <strong>short</strong> (e.g 50ms), <strong>configurable interval</strong>.
Since this is many times lower than the default <code class="language-inline-text">max.poll.interval.ms</code>, while also not affected by message processing, we avoid the "rebalance storm" that plagues the <strong>poll-then-process</strong> loop.
Kafka won't mistaken our consumer as dead for not <code class="language-inline-text">poll</code>ing often enough. In addition, we would know sooner if another <strong>rebalance</strong> is going to happen.</li>
<li>When we <code class="language-inline-text">poll</code> more often, we can also use a lower <code class="language-inline-text">max.poll.interval.ms</code> to speed up the <strong>rebalance</strong> process.</li>
<li>For each <code class="language-inline-text">TopicPartition</code> that the <strong>Executor</strong> cannot keep up with the rate of incoming messages, its corresponding work queue will become full and <strong>back-pressure</strong> the <strong>Poller</strong>.
The <strong>Poller</strong> would need to selectively <a href="https://kafka.apache.org/28/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html#pause(java.util.Collection)" target="_blank" rel="nofollow noopener noreferrer">pause</a> this <code class="language-inline-text">TopicPartition</code>, so that subsequent <code class="language-inline-text">poll</code>s <strong>won't pull in</strong> more messages from it.
When the queue is freed up again, it would <a href="https://kafka.apache.org/28/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html#resume(java.util.Collection)" target="_blank" rel="nofollow noopener noreferrer">resume</a> the same <code class="language-inline-text">TopicPartition</code> to get new messages starting from the next <code class="language-inline-text">poll</code>.
That's why we can keep <code class="language-inline-text">poll</code>ing. That's also why we use a short interval, so that we can "resume" faster.</li>
</ul>
<blockquote>
<p><strong>pause</strong>(Collection&#x3C;<strong>TopicPartition</strong>> partitions)</p>
<p>Suspend fetching from the requested partitions. Future calls to <strong>poll</strong>(Duration) will not return any records from these partitions until they have been resumed using <strong>resume</strong>(Collection).</p>
</blockquote>
<h3 id="executor"><a href="#executor" aria-hidden="true"><span class="icon icon-link"></span></a>Executor</h3>
<p><strong>Executor</strong> acts like a <a href="https://en.wikipedia.org/wiki/Thread_pool" target="_blank" rel="nofollow noopener noreferrer">thread pool</a>, where it maintains multiple workers to process the messages:</p>
<ul>
<li><strong>Executor</strong> and the number of workers is tunable to optimize for different workloads e.g CPU bound, I/O bound, etc.</li>
<li>Each <strong>work queue</strong> is processed by one worker.</li>
<li>One worker can be responsible for multiple <strong>work queue</strong>s.</li>
<li>For each <strong>work queue</strong>, the worker processes its messages one by one.</li>
</ul>
<p>With this setup, messages within one partition is processed <strong>in order</strong>, while messages from different partitions are processed <strong>in parallel</strong>.</p>
<h3 id="offset-manager"><a href="#offset-manager" aria-hidden="true"><span class="icon icon-link"></span></a>Offset Manager</h3>
<p>Each message in Kafka is associated with an <strong>offset</strong> - an integer number denoting its position in the current partition.
By storing this number, we essentially provide a checkpoint for our consumer. If it fails and comes back, it knows from where to continue.
As such, it is vital for implementing various processing guarantees in Kafka:</p>
<ul>
<li>For <em>at-most-once</em>, we need to save <code class="language-inline-text">$offset + 1</code> before processing <code class="language-inline-text">$offset</code>. If our consumer fails before successfully process <code class="language-inline-text">$offset</code> and restarts, it will continue from <code class="language-inline-text">$offset + 1</code> and not reprocess <code class="language-inline-text">$offset</code>.</li>
<li>For <em>at-least-once</em>, we need to successfully process <code class="language-inline-text">$offset</code> before saving <code class="language-inline-text">$offset + 1</code>. If our consumer fails before saving <code class="language-inline-text">$offset + 1</code> and restarts, it will continue from and reprocess <code class="language-inline-text">$offset</code>.</li>
<li>For <em>exactly-once</em> using an external <a href="https://kafka.apache.org/28/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html#rebalancecallback" target="_blank" rel="nofollow noopener noreferrer">transactional storage</a> - we need to process <code class="language-inline-text">$offset</code> and save <code class="language-inline-text">$offset + 1</code> within one transaction and roll back if anything goes wrong.</li>
</ul>
<p>With that in mind, we have <strong>Offset Manager</strong> providing a consistent interface for other components to work with these saved offsets:</p>
<ul>
<li>If we store offsets within Kafka, it is responsible for <strong>manually</strong> <a href="https://kafka.apache.org/28/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html#commitSync()" target="_blank" rel="nofollow noopener noreferrer">committing offsets</a>.</li>
<li>If we decide to manage offsets using an external storage, it is responsible for retrieving from and saving into that storage.</li>
<li>It allows <strong>Poller</strong> and <strong>Executor</strong> to save offsets either <strong>synchronously</strong> or <strong>asynchronously</strong> - in <a href="https://en.wikipedia.org/wiki/Fire-and-forget" target="_blank" rel="nofollow noopener noreferrer">fire and forget</a> fashion.</li>
<li><strong>Offset Manager</strong> storing behavior can be configured: in <strong>batched</strong>, <strong>recurring</strong> with a timer, etc...</li>
</ul>
<p>What about Kafka's <a href="https://docs.confluent.io/platform/current/installation/configuration/consumer-configs.html#consumerconfigs_enable.auto.commit" target="_blank" rel="nofollow noopener noreferrer">auto commit</a>? Confluent <a href="https://docs.confluent.io/platform/current/clients/consumer.html#offset-management" target="_blank" rel="nofollow noopener noreferrer">claims</a> that:</p>
<blockquote>
<p>Using auto-commit gives you “at least once” delivery: Kafka guarantees that no messages will be missed, but duplicates are possible.</p>
</blockquote>
<p>This is true for delivery, however, it doesn't provide any guarantee for processing:</p>
<ul>
<li>It's not <em>at-most-once</em>: If some messages are successfully processed, and our consumer crashes before the next auto commit event, these messages are reprocessed.</li>
<li>It's not <em>at-least-once</em>: If auto commit kicks in, and our consumer crashes right afterward, some messages are lost.</li>
</ul>
<p>Due to this, we always set <code class="language-inline-text">enable.auto.commit</code> to <code class="language-inline-text">false</code> and have <strong>Offset Manager</strong> manage offsets manually.</p>
<h2 id="achieving-processing-guarantees"><a href="#achieving-processing-guarantees" aria-hidden="true"><span class="icon icon-link"></span></a>Achieving processing guarantees</h2>
<p>Let's go through a few example use cases to see how the components work together to satisfy different processing guarantees.</p>
<h3 id="at-most-once-offsets-managed-by-kafka"><a href="#at-most-once-offsets-managed-by-kafka" aria-hidden="true"><span class="icon icon-link"></span></a>At-most-once, offsets managed by Kafka</h3>
<p><img class="g-image g-image--lazy g-image--loading" src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 693 411' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-f860433ba017d383f85c870c2afdb3cb'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-f860433ba017d383f85c870c2afdb3cb)' width='693' height='411' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAmCAYAAAB0xJ2ZAAAACXBIWXMAAAsSAAALEgHS3X78AAAGKUlEQVRo3t2ah08dRxDG779NFMdJZEVKYjuOLBQlBAKyBEIkSIQmJASIZpoNpvfeMcam92JMx9gTfivN077z3Wt0Vhpur%2b3tfjvzTXk4YrXPnz8Hjol/Jcj9e/dk%2bs2bL%2b7fpeZ4AXBwcCAJ8fES9/Sp9Pb2Sn1dvXR2dJh7nz59Ms/dFTAc94WPHz%2baY1lJqTz86Wfp6e6Wb776Wh7/8lDev38fAOqugBAEALtLe/v2rVl8/B9/yg/3v5OszEwpLysL0hTbXG4zEJ4AtLW2ym%2b/PpHy0jKz%2b0ODgzI6MiKtZ9c/fPhwp4D4ggMUhIx//pXvv70vOdnZBoQnjx7LxsaG7OzsyMrKihweHnoC4QXMrQJAJ5yXmyu/x8XJu3fvJPnvJMn%2bLyvw3MnJiayvrxuhb4Nnk%2bRt0ApPL7C/vy%2bPzkjvxwcPpLenJ%2bieaggNLVhdXZWtrS3PwW%2bDSfiawOvJ11JdVSVjY2Nh7R1eaG9vl7a2NmlsbJQXL17IwsLCrXCbjtdFe5f7%2bvoC5261tvtDQ0NSU1NjgED29vaCALipROnLAaenp6YP8dF3q7QbjImJCWloaJDq6mqjBcvLy3J8fHzjidHxs12d5NLSUpAGRGrrLH5tbS0IQDdwkchlA%2bb43dCPspN%2bALgnqV7ANiEIFbe5vb0d9ULcGnfjAAilOV5ECRBHR0eGH3Z3d32FZ8lHroI3HL%2bF2wDYHBDJZPyAAEhAAABcKNrBgjmyYAWAe5ubm4Go8zJBCAkAAge4bThWFUYAAI/R3NxsiHN2dlZ6zmKN/v5%2b00dwvZgMHBKp9p0bAL9dYyJ%2b4EQLhAJQUVEh%2bfn5kp6eLnV1dVJ2lmilpKRISUmJpKamSvxZKj43N%2bfrga5EA0Aet5aXl2eSoPOQkQ0AJmU3UmxAQCvcLRIPdOEagODC%2bHh5eblUnUWDqCfnGtycRwMAgCMLn5%2bfN6k34w8PDxv1Z%2be17hANAV8IANrYkcLCQmlpaTEgcF5QUGBC3YsAgEalibHZ%2bampKaNtAwMDJppcXFy8Hg3Qo016th3Gao9eGkBj158/fy719fWGF2prawNaduUa4Bd42Lvg5SbDuUI3cUKC2sgkx8fHZXJy0ghegTjhWgBwT9QvDvCbjNf7blNhHADFz9ta5k7EEFJs9UBXGgdEGgn6hcBu0YUT7DQ1NZk0maoSQDA2R1u4hvDMVdQVnHCJSLhcIFzTognMbptSLPwR6XPRiBNuAl4A2AARuhLJdXd3m3iBI3ZdWVlpoj2ITeuH0U4ulsVHrQF2/E3sbSclNEjLKxfQI6zNQlk8/nxkZMS4OFxmR0eHUXsd6zJTXB2PGMZeB6anOYd9zjPUM52uri7jj3FHBCaoKokI7g9RDfAjNgDAdxMnTE9Pm50vLS01QAAM57YGXEazF0/%2bAHlCoqyDwIq4gnMEDkJ4hvU5/GGBtvvRxrXOzk7Pj6IVgBUqW9SKcSj%2buIjfFvQdiFOjSP0%2b5Tk7zMZc2XQaVW1Hoy5AADEtdwMMrEwUqOcqPAfSfDAS%2b/Xr22V0ux%2bNtthjMh87eUM709LSpLi4OPBsVlaWZGZmmj6a4LBIfdkuWKBOurP0ydc1jwcEd64eK8GFCqCiHQsbt0v0aENCQoJZMI3fPQEkOTk5EJM4uCgWzcO272XX4QQeYlDbhQEGIJy3EfmhYeQBJEUQ6Xl4Qn%2b5YpNGR0cNKUPEmAGR5uDgoDnX7Bbtd1gYakMmZqsPcXpubq48e/ZMcnJyjNprA%2bmZmRkDHJrAR5VZEfpcQ2MQva/lLkCHO0h%2bmAw8w/ewT%2b4BPqDrWPqejqtsrn02hPdevnxprrOZEDH5BeuDC6hWFxUVBf22yQY7XvYTrvrLB%2bEAJcNQkaCX4DUoflAIof/q1SuzM5ATk%2baaZo2Rjq/FG92EpKQkU3BRE87IyJDExMSgZCsIAF5SteajCDajfRWed9frrrvZm4iwQYDKrgMO58QlgO4LAEfUzo7HvYT7Xv8ocRkSzTd0E5UEMU%2b/zVFyJ0ZwLqLMFWuB9KJ%2bFPGKA9BegjDMCW4gKEMDCNNtondiTSJu0s9cOgcWjYZi86i%2bVp%2bpbGECeBy8jfIYbv9/p3fysHzGAR0AAAAASUVORK5CYII=' /%3e%3c/svg%3e" width="693" alt="At most once" data-srcset="/assets/static/at-most-once.c19ed0b.4c803014b443847cb8b453ce2f5c503e.png 693w" data-sizes="(max-width: 693px) 100vw, 693px" data-src="/assets/static/at-most-once.c19ed0b.4c803014b443847cb8b453ce2f5c503e.png"><noscript><img class="g-image g-image--lazy g-image--loaded" src="/assets/static/at-most-once.c19ed0b.4c803014b443847cb8b453ce2f5c503e.png" width="693" alt="At most once"></noscript></p>
<p>For <em>at-most-once</em>, we just need to commit offsets <strong>before</strong> processing the messages.
We can do it right before processing each message. However, it doesn't give us a stronger guarantee while introducing more costs.
Therefore, <strong>Poller</strong> is responsible for it. After each <code class="language-inline-text">poll</code>, it will tell <strong>Offset Manager</strong> to save these offsets and <strong>wait</strong> for a success acknowledgement from Kafka before queuing the messages for processing.</p>
<p>Prior to a <strong>rebalance</strong> event, it just needs to send a <em>fire-and-forget</em> signal to <strong>Executor</strong> to stop processing. It then takes down the work queues and gets back to wait for <strong>rebalance</strong>.
The lost messages are those still sitting in the queues or in the middle of processing. If we want to optimize for fewer lost without affecting the duration of <strong>rebalance</strong>, we can use a smaller queue size.</p>
<h3 id="at-least-once-offsets-managed-by-kafka"><a href="#at-least-once-offsets-managed-by-kafka" aria-hidden="true"><span class="icon icon-link"></span></a>At-least-once, offsets managed by Kafka</h3>
<p><img class="g-image g-image--lazy g-image--loading" src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 693 411' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-108d028107e7cc92511aa40197db049c'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-108d028107e7cc92511aa40197db049c)' width='693' height='411' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAmCAYAAAB0xJ2ZAAAACXBIWXMAAAsSAAALEgHS3X78AAAGbUlEQVRo3t2ZiU/dRhDG/d%2b2akpbRZXaJmmqCFUthYKQQIgWiRJASAkgrnCEI%2bG%2bz0C4gwj3HSDcCVN%2bq87TPsfmnaHASovtZ7Pe/eabb2bHjljt/Pw8cEz5I1kS7tyR2ZmZT%2b7fpuZ4AXB4eCjJSUmS%2bOiR9Pf3S1Njk3R3dZl7Hz9%2bNM/dFjAc9w9nZ2fmWFFWLvd%2b%2bFH6envlqy%2b%2blAc/3ZN3794FgLotIAQBgHVpb968MYtP%2bu13%2bS7hG8nLzZXKioogptjucpOB8ASgo71dfvn5oVSWVxjrjwwPy9joqLRf/L63t3ergPhEAxSEnL/%2blm%2b/TpD8x48NCA/vP5DNzU3Z3d2V1dVVOTo68gTCC5gbBYBOuLCgQH5NTJS5uTlJ%2bzNVHv%2bTF3ju9PRUNjY2TOfcBs8WyZvACs8ocHBwIPcvRO/7u3elv68v6J4yhAYL1tbWZHt723Pwm%2bASvi4wNTkltTU18vr165D%2bji50dnZKR0eHNDc3S319vSwuLt6IsOl4/WhbeWBgIHDtprV9PjIyInV1dQYI%2bvv374MAuK5C6asBHz58MOcIH%2bduSrvBmJiYkJcvX0ptba1hwcrKipycnFx7YXT8fFcnuby8HMSAcH2dxa%2bvrwcB6AYunP65AXP8buhLsaQfAO5JahSwXQhBJWzu7OxEvBA3464dAJcxx0soAeL4%2bNjow/7%2bvm/nWfYjV6Ebjt/CbQBsDQhnMn5AACQgAAAhFHawYI4sWAHg3tbWViDr/JwgXAoAHQ1w%2b3C0FKYDABGjtbXVCOf8/Lz0XeQag4OD5pxO6MVl0JBw2RczAH5WYyJ%2b4EQKhAJQVVUlRUVFkp2dLY2NjVJxsdHKyMiQsrIyyczMlKSLrfjbt299I9CVMADkCWuFhYVmExSLGNkA4FJ2Y4sNCLDC3cKJQHFnAJ0QxssrKyul5iIbhJ5ca3ITCwMAgCMLX1hYMFtvxn/16pWhP5bXukMkAhwXALRhkeLiYmlrazMgcP3kyROT6sYDABqVJsbG8tPT04ZtQ0NDJptcWlr6fxigR1v0bD%2bM1h%2b9GEDD6s%2bePZOmpiajC8%2bfPw%2bw7MoZ4Jd42FbwCpOhQqFbOBFBbewkx8fHZXJy0nSiAnmCNp71qzN8VgbYL3LnAX5AhUpnlUEASpy3WebeiNGJPtQbIkmho2FKXDLBUC/l/0l2WlpazDaZqhJAMDZHu%2btvgIQmIJLhvicadjihEPUCwG8PgFWhsP7GkcyOBaHstiuF26hSwwZ7e817qETpO3TnGs1mywk1gVCbIW2krg0NDSapIbPr6uoyYe0ybQjV7So1446OjsqLFy9MJ2qoePb29katD46df5N725sSFSKvvYAeiRKI1%2bh/VePh4WET4hA3UtqZmRkT7yPxVfczsIoQzKJZ7NTUlAmf1B0AwBZWchh7Hbie7jnsa56BRU5PT4%2bJx4QjJgpVsSYLoysD/IRtdnZWqqurjfWxDOMBBBMkjyDnZ8KRFkntZ5kwoLLg7u5uAyzvZGwKMLiYAsX%2bAZehTsk6SKzIK7imo0F0nmF9Dn9YoB1%2btPEbL/Rq3FOltis/kQiUn6ZEKmzoA9ZEXDWL1Oo15Tk7zcY9MRKNuTuadQECiGm5G2BAlixQr%2bk8Q/zG2raw2cUQd/cLse5Sul1MuazY4lWCZ7FaeLGBycrKktLS0sA4eXl5kpuba85hgqP00Q8eWrDAqur7nLNf1308QLj36pH2yyJCtGPh43aJHgMlJyebBWtEAZC0tLRATuJgTRbNw4CgDaujCTzEoPaEAUOBi6VhNVwMP4aaiOnY2FjU4%2bmXK4zEOGyyiEa4AZkmAs217m5hv6NZFyHLpg95ekFBgaSnp0t%2bfr6hvo1sSUmJcQVEEuaE2/V5jnQmh1jil4gb/qruF87YPIPw8QULIDEO8ysvLzcRgvUBNPeYs/1tEwM76mcgpwCEyvh4CYtXWkGncLp%2bemfiT58%2bNdEHNSe8EUVgAbGd3ziGO7aOy/xZID01NdUUXNSFc3JyJCUlJWizFQQA/wTymrPrwO6X8Txs0DzhOjWMSMdAiDRWhwFck0dQcfIFgCO%2brtTz65rWRiuAsQhnqHExooqgpuReTcWdHMGJR5krmv%2bJ54cR243VOLAXV6LAgnuRNMEAMlRb6J1YrHJdPnPpHFg0DMXnob5WnxFZXICcRneXuAVa9C9XL91WSlUNlAAAAABJRU5ErkJggg==' /%3e%3c/svg%3e" width="693" alt="At least once" data-srcset="/assets/static/at-least-once.c19ed0b.e24aee3b1e85cc3f6b638d30e4eb7de8.png 693w" data-sizes="(max-width: 693px) 100vw, 693px" data-src="/assets/static/at-least-once.c19ed0b.e24aee3b1e85cc3f6b638d30e4eb7de8.png"><noscript><img class="g-image g-image--lazy g-image--loaded" src="/assets/static/at-least-once.c19ed0b.e24aee3b1e85cc3f6b638d30e4eb7de8.png" width="693" alt="At least once"></noscript></p>
<p>For <em>at-least-once</em>, we just need to make sure offsets are only saved <strong>after</strong> the messages have been processed successfully.
Consequently, if we were to process 10 messages, we wouldn't need to save offsets for all of them but only the last one.</p>
<p>In this setup, <strong>Executor</strong> will emit signals to <strong>Offset Manager</strong> each time it completes processing for a message.
<strong>Offset Manager</strong> keeps track of the latest offset for each partition - which in total is not that many - and decide <strong>when</strong> to commit them to Kafka.
For example, we can set <strong>Offset Manager</strong> to commit once every 5 seconds. This happens regardless of whether new messages are coming or not.
<em>(Interestingly, this is important for older Kafka if we don't want to lose committed offsets in a low activity Kafka topic, see <a href="https://issues.apache.org/jira/browse/KAFKA-4682" target="_blank" rel="nofollow noopener noreferrer">KAFKA-4682</a>)</em>.</p>
<p>Prior to a <strong>rebalance</strong> event, <strong>Poller</strong> set a hard <strong>deadline</strong> and notifies <strong>Executor</strong> to wrap up its <strong>in-flight</strong> processing and <strong>Offset Manager</strong> to follow up with a <strong>last</strong> commit.
If the deadline has passed, or <strong>Poller</strong> has received responses from others, it takes down the <strong>work queues</strong> and gets back to wait for <strong>rebalance</strong>.</p>
<p>To optimize for fewer duplicated processing, we can:</p>
<ul>
<li>Use a <strong>looser</strong> deadline, allowing more time for "wrapping up". However, it also increases timing for <strong>rebalance</strong>.</li>
<li>Set <strong>Offset Manager</strong> to commit more often.</li>
</ul>
<h3 id="exactly-once-offsets-managed-externally"><a href="#exactly-once-offsets-managed-externally" aria-hidden="true"><span class="icon icon-link"></span></a>Exactly-once, offsets managed externally</h3>
<p><img class="g-image g-image--lazy g-image--loading" src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 693 411' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-b73808922731523ccfea2d215b46970c'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-b73808922731523ccfea2d215b46970c)' width='693' height='411' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAmCAYAAAB0xJ2ZAAAACXBIWXMAAAsSAAALEgHS3X78AAAG2ElEQVRo3s2ah09VdxTH73/bppa2MU3aamtjTNNSKMREQ2hJKAIxIUDYS8DFHoqCLEXZQxkOUFDw9H1%2b6SHnPe69bzJ%2bycmd73d/Z33P%2bD1PzPj8%2bfPhMffPHMk6d05mnj078vysjlTW5/lN8P79e8nJzpYrly/L8PCwdHZ0Sn9fn3t2cHBw5gTBenRNb968kZWVFVldXXW0trbmru09iOt3795FC4Dx6dMnd6yrqZULP/woQ4OD8tUXX8rFny7I69evz5wlWKtlLC8vy8ePHx0fu7u7sr297ZQG6T2ec827UQLgJuP58%2beO%2bezf/5Dvsr6RkuJiaairPyLts6J1ux40q2N/f1/u3r0rt27dkoGBAen734p1YAm%2bAujp7pZff7kk9bV1TvsjDx/K06dPo945LS37kY6RkRHHMGNiYkJaWloc8/fu3ZOOjg65f/%2b%2bdEd4W1hYOLSWIxigDBb9/Y98%2b3WWlN644YRw6eLPzr9OywXCvommX7586Vx0cXHR3dvc3HSMPouA%2bMbGhszPzzsajLj0q1evggWgHyovK5PfrlyRFy9eSP5feXLj3xJfkztJ5vFhABo/3tvbc9cfPnxwQMc1g3P8Hj9HMChUzyGdh3cQmm8U2NnZcaD3/fnzMjw05As2p%2bHrS0tLzqRbW1udeZdFlARe2Xdhcn193TEHIRA9WuIdhBPoAtNT09LS3Czj4%2bOhoHPSYDc1NSVdXV0O0Pr7%2bw/Xmyo4e343LdA9ePAg7Y9kEuWfPHniGL99%2b7Y8fvw4am1hQBlEgRiAKXGOqajvnCTzfgIH4WtqatwRRK%2burnbWkHELsJOBlLFSPo5QFhbiADH1YxAchN/a2nJr437GBWAXTGKRrgDSwQ4AGcYRQiZrgBMVgP0tc5GDhxH5Bm5H9jYzMxOFTUFWkjELiNUWArAYkMpH7O8wYWIw8RvtwjBH4rsKgGckL2rexxmGvXi%2bip%2bpAFJdgJ2T/Bv0BsQmJydlbm5OhiK5xsNIus05ROjFxwHg4w6/XlDY0XMWEg%2bdkxVAQ0OD3Lx5UwoLC12OXldXJ9euXXMIf/36dcmOlOKkrScRgbwwX71z546Ul5e7AiJTFmCrNQb5O0LAKmJHpiJQUhYAkVfz8fr6emmOZIOYJ9f4broWgAA4wjjFCqks84%2bOjjrzR/Pad8gUACcsAB1opLKy0iUZCIHriooK6enpyYgAGHSamBvNU2pjbZSz5Pnk/KdiAbag0GH9MFl/jA1V2oXRa7Te2NgonZ2dDhfa2toOrezELSD2I36ZYKLhKCxGay2upSuNCwociKhAqWs7NrYHeRy1iBeWqvrlAUGCitetYcAgZk49rr1Hv0IMIvpYYWUi6Tm2TDCeNZDZkdTMzs66BAfmtFOLhVnSeyRDVKLkBJZxFZCldPIEL14hEiSAWI3wDuZLRqddWY6YMQyn2ktkPoT39u3bYym2vHgL8BNAUHZGQkPYbGpqcoBGWhtr3qlUg9rwpJ9HmJyennYNkUePHrnzdIDSs/k3UrZFiQKRXy1gzzFtFkijgpjOQglnvb29zu%2bD8CXR6lELI9Jn3IKmCD0B2mKEUe1dMMhhLB/UGVpz2GvewUI9JiYeE45ITEhC8FPCH6QWEKQZnsE8GoFxQhtxHUGwYBabjo%2bG/Ya16saHNjtxF1yOnoF2g8kruIboGkNaa3jaHLThRwf30GqQbzIhAgqr1cPqiDCz9zu3wGcBljWgUW2N62BdWKFNsym8ULqGZE%2bzLiZFYtyEEAxoTBao1xDv4Bb05CwwxaKyPY/HvAXSRATlFwpZF1ZsBYB1FBQUuNaZ/qakpESKi4vdOZbgwaRuKsKY7qfhS%2br7nKNxreMRhGZsqQBb2AarfZ7MfMowVmldJCcnxzGsLoJA8vPzHW9uY4RsDKZ5WXd%2b1DzABF5iUhvGEIYKLp1BFki0oNcPbrCFlc5AMfCAksAecAhswg3INIkaXGt1i/V7mnVRidnaHzBj4%2bHq1atSWlrqTMxKtqqq6nDr2W47h5G%2bq40PFqiRY2xszB0xSxYGeNnfhM2J77ODRVRAOayvtrbW1Re6M8Qz1mzdFgV7dl9dBRAv4%2bMjMK9mpdtOYWTfa29vd4vTfIFKEGAiipBHgDswl%2bj8mlazfhiE8vLyXMNFXbioqEhyc3Ojiq0oAfAjTEjjbuyilXgfa4hNcs7CQIkQCgKk0ToWwDWlPB2nQAFwxNc1Hw8ints/SqRCQfl8UH6faMaIEhUEwbUgS1Zwx828TLS5kk1okmEqkfmtG6tysF5cjIwUlyMpwwIAXgv0XqpFxGntFsfbPsdC8XmsSLvPdLZwAbBFd5NxC3DmP5Ieyzh%2bJwXRAAAAAElFTkSuQmCC' /%3e%3c/svg%3e" width="693" alt="Exactly once" data-srcset="/assets/static/exactly-once.c19ed0b.ee2808cf87a3ed8198eed48ab6d53d86.png 693w" data-sizes="(max-width: 693px) 100vw, 693px" data-src="/assets/static/exactly-once.c19ed0b.ee2808cf87a3ed8198eed48ab6d53d86.png"><noscript><img class="g-image g-image--lazy g-image--loaded" src="/assets/static/exactly-once.c19ed0b.ee2808cf87a3ed8198eed48ab6d53d86.png" width="693" alt="Exactly once"></noscript></p>
<p>In this case, offset saving and message processing needs to happen within one transaction. This means <strong>Executor</strong> and <strong>Offset Manager</strong> working closely together using <strong>synchronous</strong> calls to make it happen.</p>
<p>Following a <strong>rebalance</strong> event, <strong>Poller</strong> asks <strong>Offset Manager</strong> for the saved offsets of current assignments. It then <a href="https://kafka.apache.org/28/javadoc/org/apache/kafka/clients/consumer/KafkaConsumer.html#seek(org.apache.kafka.common.TopicPartition,long)" target="_blank" rel="nofollow noopener noreferrer">seek</a>s to restore the saved positions before resuming to <code class="language-inline-text">poll</code>.</p>
<blockquote>
<p>public void <strong>seek</strong>(TopicPartition partition, long offset)</p>
<p>Overrides the fetch offsets that the consumer will use on the next poll(timeout).</p>
</blockquote>
<p>Prior to a <strong>rebalance</strong> event, <strong>Poller</strong> notifies <strong>Executor</strong> and waits for its response.
<strong>Executor</strong> rolls back its <strong>in-flight</strong> transactions and return to <strong>Poller</strong>.
<strong>Poller</strong> then takes down the work queues and gets back to wait for <strong>rebalance</strong>.</p>
<h2 id="conclusion"><a href="#conclusion" aria-hidden="true"><span class="icon icon-link"></span></a>Conclusion</h2>
<p>We analyze the various issues with the <strong>loop-then-process</strong> loop and come up with a more proper model for understanding and implementing Kafka Consumer.
The downside is that it is much more complicated, and probably not easy for beginners. We blame this complexity on Kafka and its low level API.</p>
<p>In practice, we probably won't do it ourselves but use a ready-made library that may or may not base on similar models: <a href="https://doc.akka.io/docs/alpakka-kafka/current/home.html" target="_blank" rel="nofollow noopener noreferrer">Alpakka Kafka</a>, <a href="https://spring.io/projects/spring-kafka" target="_blank" rel="nofollow noopener noreferrer">Spring for Kafka</a>, <a href="https://github.com/zio/zio-kafka" target="_blank" rel="nofollow noopener noreferrer">zio-kafka</a>, etc...
Even then, the proposed model can be useful for evaluating these solutions or implementing new ones.</p>
</div></main></div>
    <script src="/assets/js/app.185c96bb.js" defer></script><script src="/assets/js/page--src--templates--doc-vue.fff5180d.js" defer></script>
  </body>
</html>
